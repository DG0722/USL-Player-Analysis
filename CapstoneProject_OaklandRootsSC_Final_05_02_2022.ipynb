{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa89bba7",
   "metadata": {},
   "source": [
    "# Capstone Project: Oakland Roots SC\n",
    "\n",
    "Team information(Alphabetize)\n",
    "- Member: Denggao Jiang\n",
    "- Project Summary: \n",
    "\n",
    "Member information(Alphabetize)\n",
    "- Family Name: Denggao\n",
    "- Given Name: Jiang\n",
    "- ID: ####\n",
    "- Student email: ##########\n",
    "\n",
    "Programming Language: Python 3.9 in Jupyter Notebook\n",
    "\n",
    "Python Libraries used:\n",
    "- pandas\n",
    "- numpy\n",
    "- requests\n",
    "- json\n",
    "- csv\n",
    "- re\n",
    "- time\n",
    "- lxml\n",
    "- os\n",
    "- calendar\n",
    "- missingno\n",
    "- pandas_profiling\n",
    "- sklearn\n",
    "- matplotlib\n",
    "- plotly\n",
    "- ipywidgets\n",
    "- warnings\n",
    "- dash\n",
    "- jupyter_dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345598ef",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"sec_0\"></a>\n",
    "\n",
    "* [Executive Summary](#sec_1)\n",
    "* [Data introduction](#sec_2)\n",
    "* [Webscrape and Dataset Retrieve](#sec_3)\n",
    " * [Wyscout Dataset](#sec_3.1)\n",
    " * [ASA Dataset](#sec_3.2)\n",
    " * [TransferMarkt Dataset Webscrape](#sec_3.3)\n",
    "   * [Get a total of 6 pages of players' information](#sec_3.3.1)\n",
    "   * [Foreigner player information](#sec_3.3.2)\n",
    " * [Sofa Score Dataset Webscrape (2020&2021)](#sec_3.4)\n",
    "* [Data Manipulation & EDA Analysis](#sec_4)\n",
    " * [Position Integration](#sec_4.1)\n",
    " * [Wyscout Data Cleaning (Position and Market Value)](#sec_4.2)\n",
    " * [ASA Dataset Merge and Data Cleaning](#sec_4.3)\n",
    " * [TransferMarkt Data Cleaning](#sec_4.4)\n",
    " * [Combine Wyscout and Ratings Dataset](#sec_4.5)\n",
    " * [Data Analysis](#sec_4.6)\n",
    " * [Data Visualization](#sec_4.7)\n",
    "* [Features Selection (Wyscout Dataset)](#sec_5)\n",
    " * [Split Dataset with Positions](#sec_5.1)\n",
    " * [Deploy Random Forest Algorithm](#sec_5.2)\n",
    "* [Cosine Distance](#sec_6)\n",
    " * [Radar Plot](#sec_6.1)\n",
    "   * [Player comparison engine](#sec_6.1.1)\n",
    " * [Another Way Cosine Distance](#sec_6.2)\n",
    "   * [Position FB -- Most similar players to R. Cannon](#sec_6.2.1)\n",
    "   * [Position CB -- Most similar players to J. Sands](#sec_6.2.2)\n",
    "   * [Position CM -- Most similar players to J. Sands & C. Bassett](#sec_6.2.3)\n",
    "   * [Position AM -- Most similar players to C. Bassett](#sec_6.2.4)\n",
    "   * [Position CF -- Most similar players to R. Damus & C. Bassett](#sec_6.2.5)\n",
    "   * [Summary](#sec_6.2.6)\n",
    "   * [Find Player Information](#sec_6.2.7)\n",
    "* [Rating Model](#sec_7)\n",
    "* [Market Value Model](#sec_8)\n",
    " * [Market Value Forecast](#sec_8.1)\n",
    " * [Market Value supplement](#sec_8.2)\n",
    "   * [Before supplement](#sec_8.2.1)\n",
    "   * [After supplement](#sec_8.2.2)\n",
    "* [Abandon cases](#sec_9)\n",
    " * [The Neural Network Model to Predict the Market Value](#sec_9.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26491f",
   "metadata": {},
   "source": [
    "## 1. Executive Summary <a class=\"anchor\" id=\"sec_1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedabd32",
   "metadata": {},
   "source": [
    "### Problem  \n",
    "Oakland Roots needs help recruiting talented soccer players to their team. In particular, they are looking to find players with skillsets lacking in the Roots team and at an affordable price.  \n",
    "### Solution  \n",
    "With data sourced and scraped from soccer statistics websites, we have provided a comprehensive analysis/plan of attack for Oakland Roots. We delve into player statistics, team dynamics, field layouts, and feature/skillset importance to make better-informed recruitment decisions.  \n",
    "### Highlights  \n",
    "Using various analytic techniques, we uncovered resources & statistics that provide the Oakland Roots team strategies to recruit talent. These include 3 main categories (1) Talent-based recruitments (based on specific features of desired players), (2) Similarity-based recruitment (comparing to other players), and (3) Team-based recommendations & blindspots (based on what team dynamics lead to winning championships). More specifically, we this breaks down into these loosely-grouped analytic categories:\n",
    "  \n",
    "1. Undervalued Players (Market Value Model)   \n",
    "2. Similar Players (Cosine Similarity)   \n",
    "3. Important Features of Valuable Players (Random Forest) \n",
    "4. Important Features Per Position \n",
    "5. Team-by-Team Comparisons \n",
    "6. Statistics by Features \n",
    "7. Player Country of Origin (Choropleth)\n",
    "8. Radar Plots Comparing Most Similar Players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d3586",
   "metadata": {},
   "source": [
    "## 2. Data introduction <a class=\"anchor\" id=\"sec_2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b6ef3",
   "metadata": {},
   "source": [
    "### Wyscout dataset (Wy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda42bd",
   "metadata": {},
   "source": [
    "The Wyscout dataset is retrieved from the Wyscout data platform as provided by the client (Jordan). Wyscout is the largest soccer data database on the internet. It compares players in the USL League One — ranking players by shots, crosses, & successful tackles in the USL Championship Games. Moreover, they have team statistics — correlation stats of formation play & winning rate of each team for multiple or singular games. Statistics range from broad (team/games level) to narrow (players/minute-by-minute level). We acquired 2020 & 2021 datasets on all the players in USL League One — extracting player positions, features, & statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ba736",
   "metadata": {},
   "source": [
    "### American Soccer Analysis (ASA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42994398",
   "metadata": {},
   "source": [
    "The American Soccer Analysis (ASA) dataset is downloaded to visualize the data. The dataset contains three separate datasets of xGoals, xPass, and Goals Added (g+). The metric xGoals (xG) assesses the probability (%) of any shot scoring (a goal). Specifically, it quantifies the difficulty of a scoring shot using various predictive metrics — players' goals, key passes, & assists. Likewise, the metric xPass (xP) assesses the probability (%) of a pass being successful (making it to a teammate). Other columns include — passing percentage (%), number of passes (#), passing distance (m), & player's touch percentage of the ball (%). The Goals Added (g+) dataset measures a player's total contribution in attack & defense during gameplay. Each column in the dataset are factors — dribbling, fouling, passing, & receiving — can affect a team's chance to score or overturn possession. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6af4ed",
   "metadata": {},
   "source": [
    "### Transfermarkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b2bc8",
   "metadata": {},
   "source": [
    "Transfermarkt is a website where anyone can look up a soccer team with player statistics, game stats, & a player's market value ($). The market value on Transfermarkt is determined by the administrator in charge of each regional league & a data scout. Aforesaid data scout considers factors like (1) the level of the league the player is in, (2) the player's position, (3) age, & (4) recent trading bids from other teams (higher bids increase market value). The market value is helpful for sports managers of a team to get an idea of a player's skill level. We webscraped every player's statistics—including market value—from the website. This dataset was primarily combined with Wyscout's and ASA datasets (matching by player names) for modeling and visualization purposes. This data was then used in a Moneyball-like attempt to identify undervalued players according to their skill level & market value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfce11",
   "metadata": {},
   "source": [
    "### Sofa Score Dataset (2020 & 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0683c",
   "metadata": {},
   "source": [
    "We found ratings of each player in the USL League One on a website called SofaScore. This website built an algorithm that quantifies a player's performance by aggregating player statistics into one “rating”. The SofaScore ratings for 2020 and 2021 were scraped from the site. This dataset was merged with Wyscout to construct feature selection, ratings, and a salary model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3e370",
   "metadata": {},
   "source": [
    "## 3. Webscrape and Dataset Retrieve <a class=\"anchor\" id=\"sec_3\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987c920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dg/opt/anaconda3/lib/python3.7/site-packages/google/colab/data_table.py:30: UserWarning:\n",
      "\n",
      "IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.6.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from lxml import etree\n",
    "import os\n",
    "import calendar\n",
    "import missingno as msno\n",
    "import pandas_profiling as pf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import ipywidgets as widgets\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings ('ignore')\n",
    "\n",
    "from dash import Dash, dcc, html, dcc, Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac680b37",
   "metadata": {},
   "source": [
    "### 3.1 Wyscout Dataset <a class=\"anchor\" id=\"sec_3.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020 = pd.read_excel('datasets/Data_Wy_2020.xlsx')\n",
    "Data_Wy_2021 = pd.read_excel('datasets/Data_Wy_2021.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c7a79",
   "metadata": {},
   "source": [
    "### 3.2 ASA Dataset <a class=\"anchor\" id=\"sec_3.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e266ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g = pd.read_csv('datasets/american_soccer_analysis_usl1_xgoals_players_2022-03-21.csv').dropna(axis=1, how=\"all\")\n",
    "data_p = pd.read_csv('datasets/american_soccer_analysis_usl1_xpass_players_2022-03-21.csv').dropna(axis=1, how=\"all\")\n",
    "data_g_a = pd.read_csv('datasets/american_soccer_analysis_usl1_goals-added_players_2022-03-21.csv').dropna(axis=1, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61195a1b",
   "metadata": {},
   "source": [
    "### 3.3 TransferMarkt Dataset Webscrape <a class=\"anchor\" id=\"sec_3.3\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88de8e",
   "metadata": {},
   "source": [
    "#### 3.3.1 Get a total of 6 pages of players' information <a class=\"anchor\" id=\"sec_3.3.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0604b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create path\n",
    "def get_request():\n",
    "    if not os.path.exists('./datasets'):\n",
    "        os.mkdir('./datasets')\n",
    "        \n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\"}\n",
    "    for i in range(1, 7):\n",
    "        url = 'https://www.transfermarkt.us/usl-league-one/torschuetzenliste/wettbewerb/USC3/ajax/yw1/saison_id/2020/altersklasse/alle/detailpos//plus/1/page/{}?ajax=yw1'.format(i)\n",
    "        html = requests.get(url, headers=headers).text\n",
    "        get_parse(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23092bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time(input_time):\n",
    "    year = input_time.split(',')[-1].strip()\n",
    "    month = str(list(calendar.month_abbr).index(input_time.split(' ')[0]))\n",
    "\n",
    "    if int(month) < 10:\n",
    "        month = '0' + str(month)\n",
    "\n",
    "    day = int(input_time.split(',')[0].split(' ')[-1])\n",
    "    if day < 10:\n",
    "        day = '0' + str(day)\n",
    "    get_day = str(year) + '-' + str(month) + '-' + str(day)\n",
    "\n",
    "    return get_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5397d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parse(html):\n",
    "    try:\n",
    "        df = pd.read_csv('./datasets/data_TansferMarkt_2021.csv')['player_href'].values\n",
    "    except:\n",
    "        df=''\n",
    "    \n",
    "    data = etree.HTML(html)\n",
    "    year = '2021'\n",
    "    competition = 'USL1'\n",
    "    trs = data.xpath('//table[@class=\"items\"]/tbody/tr')\n",
    "    for tr in trs:\n",
    "        headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\",}\n",
    "        # Player Details Page\n",
    "        player_href = 'https://www.transfermarkt.us' + tr.xpath('./td[2]//a/@href')[0].strip()\n",
    "        if player_href in df:\n",
    "            pass\n",
    "        else:\n",
    "            #Player_name\n",
    "            player_name = tr.xpath('./td[2]//a/@title')[0].strip()\n",
    "            \n",
    "            #Position\n",
    "            position = tr.xpath('./td[2]/table/tr[2]/td/text()')[0].strip()\n",
    "            \n",
    "            #National\n",
    "            nat = '-'.join(tr.xpath('./td[3]/img/@title'))\n",
    "            \n",
    "            #Age\n",
    "            age = tr.xpath('./td[4]/text()')[0].strip()\n",
    "            \n",
    "            #Club\n",
    "            try:\n",
    "                club = tr.xpath('./td[5]/a/@title')[0].strip()\n",
    "            except:\n",
    "                club = tr.xpath('./td[5]/text()')[0].strip()\n",
    "\n",
    "            #Appearances\n",
    "            appearances = tr.xpath('./td[6]/a/text()')[0].strip()\n",
    "            \n",
    "            #Assists\n",
    "            assists = tr.xpath('./td[7]/text()')[0].strip()\n",
    "            \n",
    "            #Penalty_kicks\n",
    "            penalty_kicks = tr.xpath('./td[8]/text()')[0].strip()\n",
    "            \n",
    "            #Minutes_played\n",
    "            minutes_played = tr.xpath('./td[9]/text()')[0].strip().replace('\\'', '').replace(',', '').replace('.', '')\n",
    "\n",
    "            #Minutes_per_goals\n",
    "            minutes_per_goals = tr.xpath('./td[10]/text()')[0].strip().replace('\\'', '').replace(',', '').replace('.', '')\n",
    "\n",
    "            #goals_per_match\n",
    "            goals_per_match = tr.xpath('./td[11]/text()')[0].strip()\n",
    "            \n",
    "            #Goals\n",
    "            goals = tr.xpath('./td[12]/a/text()')[0].strip()\n",
    "            \n",
    "            # More detail page\n",
    "            re_html = requests.get(player_href, headers=headers).text\n",
    "            re_data = etree.HTML(re_html)\n",
    "\n",
    "            #Birthdate\n",
    "            try:\n",
    "                date_br = re.findall(\"\"\"birthDate\".*?class=\"data-header__content\">(.*?)</span>\"\"\", re_html, re.S)\n",
    "                Birthdate = date_br[0].split('(')[0].strip()\n",
    "                Birthdate = change_time(Birthdate)\n",
    "            except:\n",
    "                Birthdate = ''\n",
    "            \n",
    "            #Height\n",
    "            try:\n",
    "                Height = re.findall(\"\"\"Height:.*?<span itemprop=\"height\" class=\"data-header__content\">(.*?)</span>\"\"\",\n",
    "                                    re_html, re.S)\n",
    "                Height = Height[0].replace(',', '.').replace('m', '').strip()\n",
    "            except:\n",
    "                Height = ''\n",
    "            if Height == position:\n",
    "                Height = ''\n",
    "            \n",
    "            #League level\n",
    "            try:\n",
    "                League_level = re.findall(\n",
    "                    \"\"\"League level:.*?<span class=\"data-header__content\">.*?<img src=\".*?\" title=\"United States\" alt=\"United States\" class=\"flaggenrahmen\" />(.*?)</span>.*?</span>\"\"\",\n",
    "                    re_html, re.S)[0].strip()\n",
    "            except:\n",
    "                League_level = ''\n",
    "            \n",
    "            #Salary\n",
    "            Salary = ''.join(re_data.xpath('//div[@class=\"data-header__box--small\"]/a//text()')[:3]).strip().replace(\n",
    "                '$','').replace('Th.', '000')\n",
    "            \n",
    "            #Salary Date\n",
    "            try:\n",
    "                Salary_date = re_data.xpath('//div[@class=\"data-header__box--small\"]/a/p/text()')[0].split(':')[-1].strip()\n",
    "                Salary_date = change_time(salary_date)\n",
    "            except:\n",
    "                Salary_date = ''\n",
    "            \n",
    "            #Contract date(until)\n",
    "            try:\n",
    "                contract_until = re.findall('regular\">Contract expires:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "                contract_until = change_time(contract_until)\n",
    "            except:\n",
    "                contract_until = ''\n",
    "            \n",
    "            #Position detail\n",
    "            try:\n",
    "                position_detail = re.findall('regular\">Position:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "            except:\n",
    "                position_detail = ''\n",
    "                \n",
    "            #Player agent\n",
    "            try:\n",
    "                player_agent = re.findall('regular\">Player agent:</span>.*?<a.*?>(.*?)</a>', re_html, re.S)[0].strip()\n",
    "                if 'img' in player_agent:\n",
    "                    player_agent = re.findall('regular\">Player agent:</span>.*?>(.*?)</.*?>', re_html, re.S)[0].strip().replace('<span>','')\n",
    "            except:\n",
    "                player_agent = ''\n",
    "                \n",
    "            #Date of last contract extension\n",
    "            try:\n",
    "                date_of_last_contract_extension = re.findall('>Date of last contract extension:</span>.*?\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "                date_of_last_contract_extension = change_time(date_of_last_contract_extension)\n",
    "            except:\n",
    "                date_of_last_contract_extension = ''\n",
    "                \n",
    "            #Joined date\n",
    "            try:\n",
    "                joined = re.findall('regular\">Joined:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "                joined = change_time(joined)\n",
    "            except:\n",
    "                joined = ''\n",
    "                \n",
    "            #Highest salary -- Highest market value\n",
    "            try:\n",
    "                Highest_market_value = re_data.xpath('//div[@class=\"tm-player-market-value-development__max\"]/div[@class=\"tm-player-market-value-development__max-value\"]/text()'\n",
    "                                                    )[0].strip().replace('$', '').replace('Th.', '000')\n",
    "            except:\n",
    "                Highest_market_value = ''\n",
    "                \n",
    "            #Date of highest value\n",
    "            try:\n",
    "                Date_of_Highest_Value = \\\n",
    "                re_data.xpath('//div[@class=\"tm-player-market-value-development__max\"]/div[2]/text()')[\n",
    "                    0].strip()\n",
    "                Date_of_Highest_Value = change_time(Date_of_Highest_Value)\n",
    "            except:\n",
    "                Date_of_Highest_Value = ''\n",
    "\n",
    "            headers = ['Year', 'Competition', 'Player Name', 'Nat.', 'Age', 'Height(Unit:m)', \n",
    "                       'Birthdate', 'Club', 'Position', 'Position Detail', 'Appearances', 'Assists', 'Penalty Kicks', \n",
    "                       'Minutes Played', 'Minutes Per Goals', 'Goals Per Match', 'Goals', 'League Level',\n",
    "                       'Salary', 'Salary Date', 'Joined Date', 'Contract Until', 'Player Agent', 'Date of Last Contract Extension', \n",
    "                       'Highest Market Value', 'Date of Highest Value', 'player_href']\n",
    "            \n",
    "            get_values = [year, competition, player_name, nat, age, Height, \n",
    "                          Birthdate, club, position, position_detail, appearances, assists, penalty_kicks, \n",
    "                          minutes_played, minutes_per_goals, goals_per_match, goals, League_level, \n",
    "                          Salary, Salary_date, joined, contract_until, player_agent, date_of_last_contract_extension,\n",
    "                          Highest_market_value, Date_of_Highest_Value, player_href]\n",
    "            \n",
    "\n",
    "            with open('./datasets/data_TansferMarkt_2021.csv', 'a', encoding='utf_8_sig', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                with open('./datasets/data_TansferMarkt_2021.csv', 'r', encoding='utf_8_sig', newline='') as f:\n",
    "                    reader = csv.reader((line.replace('\\0', '') for line in f))\n",
    "                    if not [row for row in reader]:\n",
    "                        writer.writerow(headers)\n",
    "                        writer.writerow(get_values)\n",
    "                    else:\n",
    "                        writer.writerow(get_values)\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d95f1",
   "metadata": {},
   "source": [
    "#### 3.3.2 Foreigner player information <a class=\"anchor\" id=\"sec_3.3.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ba5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreigners_request():\n",
    "    if not os.path.exists('./datasets'):\n",
    "        os.mkdir('./datasets')\n",
    "\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\",}\n",
    "    url = 'https://www.transfermarkt.us/usl-league-one/gastarbeiter/wettbewerb/USC3/saison_id/2020'\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    foreigners_parse(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afefb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreigners_parse(html):\n",
    "    data = etree.HTML(html)\n",
    "    year = '2021'\n",
    "    competition = 'USL1'\n",
    "    trs = data.xpath('//div[@class=\"responsive-table\"]/div[@class=\"grid-view\"]/table/tbody/tr')\n",
    "    print(\"Foreigners Part\")\n",
    "    for tr in trs:\n",
    "        headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36\"}\n",
    "\n",
    "        player_href = 'https://www.transfermarkt.us' + tr.xpath('./td[4]//td[@class=\"hauptlink\"]/a/@href')[0].strip()\n",
    "        \n",
    "        #Palyer_name\n",
    "        player_name = tr.xpath('./td[4]//a/@title')[0].strip()\n",
    "        \n",
    "        #Position\n",
    "        position = tr.xpath('./td[4]/table/tr[2]/td/text()')[0].strip()\n",
    "        \n",
    "        #National\n",
    "        nat = tr.xpath('./td[1]/a/@title')[0]\n",
    "        \n",
    "        #Club\n",
    "        try:\n",
    "            club = tr.xpath('./td[5]/a/@title')[0].strip()\n",
    "        except:\n",
    "            club = tr.xpath('./td[5]/text()')[0].strip()\n",
    "        \n",
    "        #Age. The age attribute is handled in the player's personal details page, in the second subsection.\n",
    "        \n",
    "        #Personal pages\n",
    "        #Appearences; Assists; Penalty_kicks; Minutes_played; Minutes_per_goals; Goals_per_match; Goals\n",
    "        \n",
    "        re_html = requests.get(player_href, headers=headers).text\n",
    "        re_data = etree.HTML(re_html)\n",
    "        appearances, assists, penalty_kicks, minutes_played, minutes_per_goals, goals_per_match, goals = '', '', '', '', '', '', ''\n",
    "\n",
    "        trs = re_data.xpath('//div[@class=\"grid-view\"]/table/tbody/tr')\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                if tr.xpath('./td[2]/a/@title')[0] == 'USL1':\n",
    "                    appearances = tr.xpath('./td[3]/a/text()')[0].strip()\n",
    "                    assists = tr.xpath('./td[5]/text()')[0].strip()\n",
    "                    penalty_kicks = ''\n",
    "                    minutes_played = tr.xpath('./td[7]/text()')[0].strip().replace('\\'', '').replace(',', '').replace('.', '')\n",
    "                    minutes_per_goals = tr.xpath('./td[6]/text()')[0].strip()\n",
    "                    goals_per_match = ''\n",
    "                    goals = tr.xpath('./td[4]/text()')[0].strip()\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #Birthdate\n",
    "        try:\n",
    "            date_br = re.findall(\"\"\"birthDate\".*?class=\"data-header__content\">(.*?)</span>\"\"\", re_html, re.S)\n",
    "            Birthdate = date_br[0].split('(')[0].strip()\n",
    "            Birthdate = change_time(Birthdate)\n",
    "        except:\n",
    "            Birthdate = ''\n",
    "        \n",
    "        #Height\n",
    "        try:\n",
    "            Height = re.findall(\"\"\"Height:.*?<span itemprop=\"height\" class=\"data-header__content\">(.*?)</span>\"\"\",\n",
    "                                re_html, re.S)\n",
    "            Height = Height[0].replace(',', '.').replace('m', '').strip()\n",
    "        except:\n",
    "            Height = ''\n",
    "        \n",
    "        #League level\n",
    "        try:\n",
    "            League_level = re.findall(\n",
    "                \"\"\"League level:.*?<span class=\"data-header__content\">.*?<img src=\".*?\" title=\"United States\" alt=\"United States\" class=\"flaggenrahmen\" />(.*?)</span>.*?</span>\"\"\",\n",
    "                re_html, re.S)[0].strip()\n",
    "        except:\n",
    "            League_level = ''\n",
    "  \n",
    "        #Salary\n",
    "        Salary = ''.join(re_data.xpath('//div[@class=\"data-header__box--small\"]/a//text()')[:3]).strip().replace(\n",
    "            '$','').replace('Th.', '000')\n",
    "        \n",
    "        #Salary Date\n",
    "        try:\n",
    "            Salary_date = re_data.xpath('//div[@class=\"data-header__box--small\"]/a/p/text()')[0].split(':')[-1].strip()\n",
    "            Salary_date = change_time(salary_date)\n",
    "        except:\n",
    "            Salary_date = ''\n",
    "            \n",
    "        #Contract date(until)\n",
    "        try:\n",
    "            contract_until = re.findall('regular\">Contract expires:</span>.*?bold\">(.*?)</span>', re_html, re.S)[\n",
    "                0].strip()\n",
    "            contract_until = change_time(contract_until)\n",
    "        except:\n",
    "            contract_until = ''\n",
    "\n",
    "        #Position detail\n",
    "        try:\n",
    "            position_detail = re.findall('regular\">Position:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "        except:\n",
    "            position_detail = ''\n",
    "        \n",
    "        #Player agent\n",
    "        try:\n",
    "            player_agent = re.findall('regular\">Player agent:</span>.*?<a.*?>(.*?)</a>', re_html, re.S)[0].strip()\n",
    "            if 'img' in player_agent:\n",
    "                player_agent = re.findall('regular\">Player agent:</span>.*?>(.*?)</.*?>', re_html, re.S)[0].strip().replace('<span>','')\n",
    "        except:\n",
    "            player_agent = ''\n",
    "            \n",
    "        #Age\n",
    "        try:\n",
    "            age = re.findall('regular\">Age:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "        except:\n",
    "            age = ''\n",
    "        \n",
    "        #Date of last contract extension\n",
    "        try:\n",
    "            date_of_last_contract_extension = re.findall('>Date of last contract extension:</span>.*?\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "            date_of_last_contract_extension = change_time(date_of_last_contract_extension)\n",
    "        except:\n",
    "            date_of_last_contract_extension = ''\n",
    "        \n",
    "        #Joined date\n",
    "        try:\n",
    "            joined = re.findall('regular\">Joined:</span>.*?bold\">(.*?)</span>', re_html, re.S)[0].strip()\n",
    "            joined = change_time(joined)\n",
    "        except:\n",
    "            joined = ''\n",
    "            \n",
    "        #Highest salary -- Highest market value\n",
    "        try:\n",
    "            Highest_market_value = re_data.xpath(\n",
    "                '//div[@class=\"tm-player-market-value-development__max\"]/div[@class=\"tm-player-market-value-development__max-value\"]/text()')[\n",
    "                0].strip().replace('$', '').replace('Th.', '000')\n",
    "        except:\n",
    "            Highest_market_value = ''\n",
    "        \n",
    "        #Date of highest value\n",
    "        try:\n",
    "            Date_of_Highest_Value = re_data.xpath('//div[@class=\"tm-player-market-value-development__max\"]/div[2]/text()')[\n",
    "                    0].strip()\n",
    "            Date_of_Highest_Value = change_time(Date_of_Highest_Value)\n",
    "        except:\n",
    "            Date_of_Highest_Value = ''\n",
    "        \n",
    "        \n",
    "\n",
    "        headers = ['Year', 'Competition', 'Player Name', 'Nat.', 'Age', 'Height(Unit:m)', \n",
    "                       'Birthdate', 'Club', 'Position', 'Position Detail', 'Appearances', 'Assists', 'Penalty Kicks', \n",
    "                       'Minutes Played', 'Minutes Per Goals', 'Goals Per Match', 'Goals', 'League Level',\n",
    "                       'Salary', 'Salary Date', 'Joined Date', 'Contract Until', 'Player Agent', 'Date of Last Contract Extension', \n",
    "                       'Highest Market Value', 'Date of Highest Value', 'player_href']\n",
    "            \n",
    "        if Height == position or Height == position_detail:\n",
    "            Height = ''\n",
    "        get_values = [year, competition, player_name, nat, age, Height, \n",
    "                      Birthdate, club, position, position_detail, appearances, assists, penalty_kicks, \n",
    "                      minutes_played, minutes_per_goals, goals_per_match, goals, League_level, \n",
    "                      Salary, Salary_date, joined, contract_until, player_agent, date_of_last_contract_extension,\n",
    "                      Highest_market_value, Date_of_Highest_Value, player_href]\n",
    "\n",
    "        with open('./datasets/data_TansferMarkt_2021.csv', 'a', encoding='utf_8_sig',newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            with open('./datasets/data_TansferMarkt_2021.csv', 'r', encoding='utf_8_sig',newline='') as f:\n",
    "                reader = csv.reader((line.replace('\\0', '') for line in f))\n",
    "                if not [row for row in reader]:\n",
    "                    writer.writerow(headers)\n",
    "                    writer.writerow(get_values)\n",
    "                else:\n",
    "                    writer.writerow(get_values)\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('datasets/data_TansferMarkt_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff575fd8",
   "metadata": {},
   "source": [
    "### 3.4 Sofa Score Dataset Webscrape (2020&2021) <a class=\"anchor\" id=\"sec_3.4\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae910935",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b108c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Infor(year,pagenum):\n",
    "    if year == '2021':\n",
    "        m_number = '36019'\n",
    "    elif year == '2020':\n",
    "        m_number = '26862'\n",
    "    page = int(pagenum)*20\n",
    "    url = 'https://api.sofascore.com/api/v1/unique-tournament/13362/season/'+str(m_number)+'/statistics?limit=20&order=-rating&offset='+str(page)+'&group=summary'\n",
    "    res = requests.get(url=url,headers=headers).text\n",
    "    res = json.loads(res)\n",
    "    results = res['results']\n",
    "    goals = []\n",
    "    successfulDribbles = []\n",
    "    tackles = []\n",
    "    assists = []\n",
    "    accuratePassesPercentages = []\n",
    "    ratings =[]\n",
    "    players =[]\n",
    "    teams =[]\n",
    "    for r in results:\n",
    "        goal = r['goals']\n",
    "        goals.append(goal)\n",
    "        \n",
    "        successfulDribble = r['successfulDribbles']\n",
    "        successfulDribbles.append(successfulDribble)\n",
    "        \n",
    "        tackle = r['tackles']\n",
    "        tackles.append(tackle)\n",
    "        \n",
    "        assist = r['assists']\n",
    "        assists.append(assist)\n",
    "        \n",
    "        accuratePassesPercentage = r['accuratePassesPercentage']\n",
    "        accuratePassesPercentages.append(accuratePassesPercentage)\n",
    "        \n",
    "        rating = r['rating']\n",
    "        ratings.append(rating)\n",
    "        \n",
    "        player = r['player']['name']\n",
    "        players.append(player)\n",
    "        \n",
    "        team = r['team']['name']\n",
    "        teams.append(team)\n",
    "    \n",
    "    return goals,successfulDribbles,tackles,assists,accuratePassesPercentages,ratings,players,teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = '2021'\n",
    "# goals = []\n",
    "# successfulDribbles=[]\n",
    "# tackles = []\n",
    "# assists= []\n",
    "# accuratePassesPercentages=[]\n",
    "# ratings = []\n",
    "# players = []\n",
    "# teams = []\n",
    "# for i in range(17):\n",
    "#     goal,successfulDribble,tackle,assist,accuratePassesPercentage,rating,player,team =Infor(year,i)\n",
    "\n",
    "#     for (g,s,ta,ass) in zip(goal,successfulDribble,tackle,assist):\n",
    "#         goals.append(g)\n",
    "#         successfulDribbles.append(s)\n",
    "#         tackles.append(ta)\n",
    "#         assists.append(ass)\n",
    "#     for (ac,r,p,te) in zip(accuratePassesPercentage,rating,player,team):\n",
    "#         accuratePassesPercentages.append(ac)\n",
    "#         ratings.append(r)\n",
    "#         players.append(p)\n",
    "#         teams.append(te)\n",
    "# dic = {\n",
    "#     'Team':teams,\n",
    "#     'Player':players,\n",
    "#     'Goal':goals,\n",
    "#     'SuccessfulDribbles':successfulDribbles,\n",
    "#     'Tackles':tackles,\n",
    "#     'Assists':assists,\n",
    "#     'AccuratePassesPercentages':accuratePassesPercentages,\n",
    "#     'Rating':ratings\n",
    "# }\n",
    "\n",
    "# df1 = pd.DataFrame(dic)\n",
    "# df1.to_csv('datasets/Data_SofaScore_2021.csv')\n",
    "# pd.read_csv('datasets/Data_SofaScore_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9214e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = '2020'\n",
    "# goals = []\n",
    "# successfulDribbles=[]\n",
    "# tackles = []\n",
    "# assists= []\n",
    "# accuratePassesPercentages=[]\n",
    "# ratings = []\n",
    "# players = []\n",
    "# teams = []\n",
    "# for i in range(14):\n",
    "#     goal,successfulDribble,tackle,assist,accuratePassesPercentage,rating,player,team =Infor(year,i)\n",
    "\n",
    "#     for (g,s,ta,ass,ac,r,p,te) in zip(goal,successfulDribble,tackle,assist,accuratePassesPercentage,rating,player,team):\n",
    "#         goals.append(g)\n",
    "#         successfulDribbles.append(s)\n",
    "#         tackles.append(ta)\n",
    "#         assists.append(ass)\n",
    "#         accuratePassesPercentages.append(ac)\n",
    "#         ratings.append(r)\n",
    "#         players.append(p)\n",
    "#         teams.append(te)\n",
    "# dic = {\n",
    "#     'Team':teams,\n",
    "#     'Player':players,\n",
    "#     'Goal':goals,\n",
    "#     'SuccessfulDribbles':successfulDribbles,\n",
    "#     'Tackles':tackles,\n",
    "#     'Assists':assists,\n",
    "#     'AccuratePassesPercentages':accuratePassesPercentages,\n",
    "#     'Rating':ratings\n",
    "# }\n",
    "\n",
    "# df2 = pd.DataFrame(dic)\n",
    "# df2.to_csv('datasets/Data_SofaScore_2020.csv')\n",
    "# pd.read_csv('datasets/Data_SofaScore_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed87569",
   "metadata": {},
   "source": [
    "## 4. Data Manipulation & EDA Analysis <a class=\"anchor\" id=\"sec_4\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43d296",
   "metadata": {},
   "source": [
    "### 4.1 Position Integration <a class=\"anchor\" id=\"sec_4.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf38420",
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = ['RB', 'RWB', 'LB', 'LWB']                               \n",
    "CB = ['LCB', 'RCB', 'CH', 'LH', 'RH','CB']                 \n",
    "CM = ['CDM', 'CM', 'M', 'DMF','RDMF','LDMF','DM','RCMF']  \n",
    "AM = ['AMC', 'AMF', 'LAMF', 'RAMF', 'AML', 'AMR', 'CAM','AM']\n",
    "W = ['WF','LWF','RWF','RM','RW','LM','LW','RS','LS']\n",
    "CF = ['CF', 'LF', 'RF', 'ST','SS','S','']\n",
    "GK = ['GK','G']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a7c4c",
   "metadata": {},
   "source": [
    "### 4.2 Wyscout Data Cleaning (Position and Market Value) <a class=\"anchor\" id=\"sec_4.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020[['Player', 'Position', 'Market value']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Market Value to USD, value*1.07\n",
    "Data_Wy_2020['Market value'] = [i*1.07 for i in Data_Wy_2020['Market value']]\n",
    "Data_Wy_2021['Market value'] = [i*1.07 for i in Data_Wy_2021['Market value']]\n",
    "\n",
    "## Classify into 7 positions\n",
    "Data_Wy_2020['FB'] = ['FB' if len(set(i.replace(' ','').split(',')) & set(FB))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['CB'] = ['CB' if len(set(i.replace(' ','').split(',')) & set(CB))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['CM'] = ['CM' if len(set(i.replace(' ','').split(',')) & set(CM))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['AM'] = ['AM' if len(set(i.replace(' ','').split(',')) & set(AM))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['W'] = ['W' if len(set(i.replace(' ','').split(',')) & set(W))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['CF'] = ['CF' if len(set(i.replace(' ','').split(',')) & set(CF))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['GK'] = ['GK' if len(set(i.replace(' ','').split(',')) & set(GK))>0 else ''  for i in Data_Wy_2020['Position']]\n",
    "Data_Wy_2020['Position'] = [\",\".join([s for s in [Data_Wy_2020['FB'][i],Data_Wy_2020['CB'][i],Data_Wy_2020['CM'][i],Data_Wy_2020['AM'][i],\n",
    "                                    Data_Wy_2020['W'][i],Data_Wy_2020['CF'][i],Data_Wy_2020['GK'][i]] if s !='']) for i in range(len(Data_Wy_2020['Position']))]\n",
    "\n",
    "Data_Wy_2021['FB'] = ['FB' if len(set(i.replace(' ','').split(',')) & set(FB))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['CB'] = ['CB' if len(set(i.replace(' ','').split(',')) & set(CB))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['CM'] = ['CM' if len(set(i.replace(' ','').split(',')) & set(CM))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['AM'] = ['AM' if len(set(i.replace(' ','').split(',')) & set(AM))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['W'] = ['W' if len(set(i.replace(' ','').split(',')) & set(W))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['CF'] = ['CF' if len(set(i.replace(' ','').split(',')) & set(CF))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['GK'] = ['GK' if len(set(i.replace(' ','').split(',')) & set(GK))>0 else ''  for i in Data_Wy_2021['Position']]\n",
    "Data_Wy_2021['Position'] = [\",\".join([s for s in [Data_Wy_2021['FB'][i],Data_Wy_2021['CB'][i],Data_Wy_2021['CM'][i],Data_Wy_2021['AM'][i],\n",
    "                                    Data_Wy_2021['W'][i],Data_Wy_2021['CF'][i],Data_Wy_2021['GK'][i]] if s !='']) for i in range(len(Data_Wy_2021['Position']))]\n",
    "\n",
    "Data_Wy_2020.to_csv('datasets/new/Data_Wy_2020_new.csv',index = 0)\n",
    "Data_Wy_2021.to_csv('datasets/new/Data_Wy_2021_new.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7dbb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020[['Player', 'Position', 'Market value', 'FB', 'CB', 'CM', 'AM', 'W', 'CF', 'GK']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b01797",
   "metadata": {},
   "source": [
    "### 4.3 ASA Dataset Merge and Data Cleaning <a class=\"anchor\" id=\"sec_4.3\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea434050",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g_a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataset with column 'player', and reset index\n",
    "data_g = data_g.sort_values(by='Player')\n",
    "data_p = data_p.sort_values(by='Player')\n",
    "data_g_a = data_g_a.sort_values(by='Player')\n",
    "\n",
    "data_g.index = range(len(data_g))\n",
    "data_p.index = range(len(data_p))\n",
    "data_g_a.index = range(len(data_g_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_g_a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [data_g,data_p,data_g_a]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0edcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine whether the column ‘player’ of two datasets are the same\n",
    "df = pd.concat([data_g['Player'], data_p['Player']], axis=1)\n",
    "df['result'] = np.where(data_g['Player'] == data_p['Player'], 'Same', 'Not Same')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6cb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same\n",
    "df.groupby('result').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 2 dataset\n",
    "data = pd.merge(data_g, data_p, on=['Player','Team','Season','Position','Minutes'])\n",
    "print('Columns of merged 2 dataset', data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# players in xgoal and xpass, not in goal_added\n",
    "e=[]\n",
    "for i in data['Player'].to_list():\n",
    "    if i in data_g_a['Player'].to_list():\n",
    "        continue\n",
    "    else:\n",
    "        e.append(i)\n",
    "\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 3 dataset\n",
    "data = pd.merge(data, data_g_a, how='left', on=['Player','Team','Season','Position','Minutes'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e047855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check\n",
    "f=data['Player'][data.isnull().T.any()]\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671313f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('datasets/data_ASA.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b33d4c",
   "metadata": {},
   "source": [
    "### 4.4 TransferMarkt Data Cleaning <a class=\"anchor\" id=\"sec_4.4\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TansferMarkt_2021 = pd.read_csv('datasets/data_TansferMarkt_2021.csv')\n",
    "data_TansferMarkt_2021[['Player Name', 'Position']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b93374",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TansferMarkt_2021 = pd.read_csv('datasets/data_TansferMarkt_2021.csv')\n",
    "\n",
    "index = re.compile(r\"[A-Z]\")\n",
    "data_TansferMarkt_2021['Position'] = [''.join(index.findall(i)) for i in data_TansferMarkt_2021['Position']]\n",
    "\n",
    "Position = []\n",
    "for i in data_TansferMarkt_2021['Position']:\n",
    "    if i in FB:\n",
    "        Position.append('FB')\n",
    "    if i in CB:\n",
    "        Position.append('CB')\n",
    "    if i in CM:\n",
    "        Position.append('CM')\n",
    "    if i in AM:\n",
    "        Position.append('AM')\n",
    "    if i in W:\n",
    "        Position.append('W')\n",
    "    if i in CF:\n",
    "        Position.append('CF')\n",
    "    if i in GK:\n",
    "        Position.append('GK')\n",
    "data_TansferMarkt_2021['Position'] = Position\n",
    "\n",
    "data_TansferMarkt_2021.to_csv('datasets/new/data_TansferMarkt_2021_new.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TansferMarkt_2021[['Player Name', 'Position']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a38246",
   "metadata": {},
   "source": [
    "### 4.5 Combine Wyscout and Ratings Dataset <a class=\"anchor\" id=\"sec_4.5\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fad7d0",
   "metadata": {},
   "source": [
    "#### 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_Data = pd.read_csv('datasets/data_SofaScore_2021.csv', usecols=['Player','Rating'])\n",
    "Wy_Data = pd.read_csv('datasets/new/Data_Wy_2021_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_Data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1890c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wy_Data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15ef689",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = re.compile(r\"[A-Z]\")\n",
    "SS_Data['Player'][SS_Data['Player']=='Luca David Mayr Falten'] = 'L. Mayr-Fälten'\n",
    "SS_Data['Player'] = [index.findall(\" \".join(i.split(' ')[:-1]))[-1] + '.' + ' ' + i.split(' ')[-1] if len(i.split(' '))>1 else i for i in SS_Data['Player']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = pd.merge(Wy_Data, SS_Data, on='Player')\n",
    "\n",
    "# find out the difference values\n",
    "Wy_Player = Wy_Data['Player'].to_list()\n",
    "New_Player = NewData['Player'].to_list()\n",
    "SS_Player = SS_Data['Player'].to_list()\n",
    "\n",
    "# In the Wy dataset, but not in the NewData dataset\n",
    "diffWyNew = [i for i in Wy_Player if i not in New_Player]\n",
    "# In the SofaScore dataset, but not in the NewData dataset\n",
    "diffSsNew = [i for i in SS_Player if i not in New_Player]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89161eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffWyNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ba70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wy_Data['Player'] = Wy_Data['Player'].replace(['Damia Viader', 'Nil Vinyals', 'J. Carrera', 'Rafael Mentzingen', 'Nicolas Firmino', 'Aime Mabika',\n",
    "                                               'C. Díaz', 'Sergi Nus', 'C. Ávilez', 'M. Méndez', 'Luis Zamudio', 'Caiser Gomes', 'Shermaine Martina',\n",
    "                                               'Manuel Ferriol', 'Enric Bernat', 'F. Pérez', 'N.  Greenidge-Duncan', 'E. Vanacore-Decker','R. Gómez',\n",
    "                                               'T.Johnson', 'Gabriel Morais', 'Y. Öttl', 'Carlos Gomez', 'Ivan Magalhães', 'Pecka', 'B. Taghvai'],\n",
    "                                              ['D. Viader', 'N. Vinyals', 'J. Carrera-Garcia', 'R. Mentzingen', 'N. Firmino','A. Mabika', 'C. Diaz',\n",
    "                                               'S. Nus', 'C. Avilez', 'M. Mendez', 'L. Zamudio', 'C. Gomes', 'S. Martina','M. Ferriol', 'E. Bernat',\n",
    "                                               'F. Perez', 'N. Greenidge-Duncan', 'E. Decker','R. Gomez', 'T. Johnson', 'G. Morais', 'Y. Ottl',\n",
    "                                               'C. Gomez', 'I. Magalhaes', 'L. Pecka', 'B. Taghvai-Najib'])\n",
    "SS_Data['Player'] = SS_Data['Player'].replace(['K. ElMedkhar', 'E. Alihodžić', 'G. Kone', 'R. Sommersall', 'R. Hees', 'D. Leon', 'J. España',\n",
    "                                               'P. Monticelli', 'Y. Galvan', 'C. Gómez', 'T. Kamara', 'B. Toyama'], \n",
    "                                              ['K. Elmedkhar', 'E. Alihodzic', 'M. Kone', 'R. Somersall', 'R. van Hees', 'C. De Leon', 'J. Espana', 'J. Monticelli',\n",
    "                                               'Y. Galvan-Mercado', 'C. Gomez', 'J. Kamara', 'J. Barriga Toyama'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c45d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = pd.merge(Wy_Data, SS_Data, on='Player')\n",
    "\n",
    "# find out the difference values\n",
    "Wy_Player = Wy_Data['Player'].to_list()\n",
    "New_Player = NewData['Player'].to_list()\n",
    "SS_Player = SS_Data['Player'].to_list()\n",
    "\n",
    "# In the Wy dataset, but not in the NewData dataset\n",
    "diffWyNew = [i for i in Wy_Player if i not in New_Player]\n",
    "# In the SofaScore dataset, but not in the NewData dataset\n",
    "diffSsNew = [i for i in SS_Player if i not in New_Player]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffWyNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff03864",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData.to_csv('datasets/data_WyScout_Rating_2021.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7551e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e1a03",
   "metadata": {},
   "source": [
    "#### 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_SofaScore_2020 = pd.read_csv('datasets/Data_SofaScore_2020.csv', usecols=['Player','Rating'])\n",
    "Data_Wy_2020 = pd.read_csv('datasets/new/Data_Wy_2020_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d14ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_SofaScore_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641dff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = re.compile(r\"[A-Z]\")\n",
    "Data_SofaScore_2020['Player'][Data_SofaScore_2020['Player']=='Luca David Mayr Falten'] = 'L. Mayr-Fälten'\n",
    "Data_SofaScore_2020['Player'] = [index.findall(\" \".join(i.split(' ')[:-1]))[-1] + '.' + ' ' + i.split(' ')[-1] if len(i.split(' '))>1 else i for i in Data_SofaScore_2020['Player']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = pd.merge(Data_Wy_2020, Data_SofaScore_2020, on='Player')\n",
    "\n",
    "# find out the difference values\n",
    "Wy_Player = Data_Wy_2020['Player'].to_list()\n",
    "New_Player = NewData['Player'].to_list()\n",
    "SS_Player = Data_SofaScore_2020['Player'].to_list()\n",
    "\n",
    "# In the Wy dataset, but not in the NewData dataset\n",
    "diffWyNew = [i for i in Wy_Player if i not in New_Player]\n",
    "# In the SofaScore dataset, but not in the NewData dataset\n",
    "diffSsNew = [i for i in SS_Player if i not in New_Player]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffWyNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020['Player'] = Data_Wy_2020['Player'].replace(['F. Carabalí', 'Damia Viader', 'Paulo Júnior', 'Nil Vinyals', 'Nicolas Firmino', \n",
    "                                                         'C. Díaz', 'C. Ávilez', 'M. Méndez', 'Lucas Coutinho', 'R. Zacarías', 'Manuel Ferriol',\n",
    "                                                         'Luis Zamudio', 'R. Somersall', 'Roberto Alarcón', 'Carlos Gomez', 'A. Gluvačević',\n",
    "                                                         'Diego Souza', 'Tiago Mendonça', 'R. Gómez', 'M. O’Sullivan', 'Kenji Tanaka',\n",
    "                                                         'G. Magana Rivera', 'AJ Valenzuela', 'A. Zuluaga', 'E. Ibišević', 'Ivan Magalhães',\n",
    "                                                         'J. Álvarez', 'P. Botello Faz'],\n",
    "                                                        ['F. Carabali', 'D. Viader', 'P. Junior', 'N. Vinyals', 'N. Firmino', 'C. Diaz',\n",
    "                                                         'C. Avilez', 'M. Mendez', 'L. Coutinho', 'R. Zacarias', 'M. Ferriol', 'L. Zamudio',\n",
    "                                                         'R. Sommersall', 'R. Alarcon', 'C. Gomez', 'A. Gluvacevic','D. Souza',\n",
    "                                                         'T. Mendonca', 'R. Gomez', \"M. O'Sullivan\", 'K. Tanaka', 'G. Rivera',\n",
    "                                                         'A. Valenzuela', 'A. Zuluaga-Silva','E. Ibisevič', 'I. Magalhaes', 'J. Alvarez',\n",
    "                                                         'P. Faz'])\n",
    "Data_SofaScore_2020['Player'] = Data_SofaScore_2020['Player'].replace(['J. DeZart', 'C. Gómez', 'C. Banks', 'T. Akinlosotu', 'M. Rivera', 'E. Decker',\n",
    "                                                                       'P. Monticelli', 'L. Forbes', 'K. Bonilla', 'I. Mare', 'B. Faz', 'R. Godoy',\n",
    "                                                                       'D. Loach'],\n",
    "                                                                      ['J. Dezart', 'C. Gomez', 'J. Banks', 'A. Akinlosotu', 'G. Rivera',\n",
    "                                                                       'E. Vanacore-Decker', 'J. Monticelli', 'J. Forbes','J. Bonilla',\n",
    "                                                                       'J. Mare', 'P. Faz', 'G. Ramos-Godoy', 'T. DeLoach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addcd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData = pd.merge(Data_Wy_2020, Data_SofaScore_2020, on='Player')\n",
    "\n",
    "# find out the difference values\n",
    "Wy_Player = Data_Wy_2020['Player'].to_list()\n",
    "New_Player = NewData['Player'].to_list()\n",
    "SS_Player = Data_SofaScore_2020['Player'].to_list()\n",
    "\n",
    "# In the Wy dataset, but not in the NewData dataset\n",
    "diffWyNew = [i for i in Wy_Player if i not in New_Player]\n",
    "# In the SofaScore dataset, but not in the NewData dataset\n",
    "diffSsNew = [i for i in SS_Player if i not in New_Player]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c354857",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffWyNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ba9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffSsNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d58091",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData.to_csv('datasets/data_WyScout_Rating_2020.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53e866",
   "metadata": {},
   "source": [
    "### 4.6 Data Analysis <a class=\"anchor\" id=\"sec_4.6\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6157693",
   "metadata": {},
   "source": [
    "#### Wyscout Exploratory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0737fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wy_Data_profile = pf.ProfileReport(Wy_Data, title = \"Wyscout Data Report 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ceb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wy_Data_profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aad4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wy_Data_profile.to_file('Wyscout Data Report 2021.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17375fd",
   "metadata": {},
   "source": [
    "#### Transfermarkt Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ff74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Transfer = pd.read_csv('datasets/new/data_TansferMarkt_2021_new.csv')\n",
    "# Transfermarkt_Data_profile = pf.ProfileReport(data_Transfer, title = \"Transfermarkt Data Report 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfermarkt_Data_profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfermarkt_Data_profile.to_file('Transfermarkt Data Report 2021.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba9986",
   "metadata": {},
   "source": [
    "#### American Soccer Analysis Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca522de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ASA = pd.read_csv('datasets/data_ASA.csv')\n",
    "# ASA_Data_profile = pf.ProfileReport(data_ASA, title = \"American Soccer Analysis Data Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d169fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASA_Data_profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b70e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASA_Data_profile.to_file('American Soccer Analysis Data Report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea0a7e",
   "metadata": {},
   "source": [
    "### 4.7 Data Visualization <a class=\"anchor\" id=\"sec_4.7\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2480680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Wy = pd.read_csv('datasets/data_WyScout_Rating_2021.csv')\n",
    "data_Sample = pd.read_csv('datasets/Data_Sample.csv')\n",
    "data_ASA = pd.read_csv('datasets/data_ASA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a76b0",
   "metadata": {},
   "source": [
    "#### Age distribution Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "age = data_Wy['Age'].value_counts()\n",
    "\n",
    "trace = go.Bar(\n",
    "    x=age.index,\n",
    "    y=age.values,\n",
    "    marker=dict(\n",
    "        color = age.values,\n",
    "        colorscale='Reds',\n",
    "        showscale=True)\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "layout = go.Layout(\n",
    "                   paper_bgcolor='rgb(243, 243, 243)',\n",
    "                   plot_bgcolor='rgb(243, 243, 243)',\n",
    "                   title='Age distribution', \n",
    "                   yaxis = dict(title = 'The number of players')\n",
    "                  )\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig['layout']['xaxis'].update(dict(title = 'Age', \n",
    "                                   tickfont = dict(size = 12)))\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_avg=data_Wy['Age'].mean()\n",
    "\n",
    "fig = px.box(data_Wy, y=\"Team within selected timeframe\", x=\"Age\",\n",
    "            title='<b>Players Age distribution by Team<b>',\n",
    "            width=750,height=750,template='ggplot2')\n",
    "fig.add_shape( \n",
    "    type=\"line\", line_color=\"black\", line_width=3, opacity=1, line_dash=\"dot\",\n",
    "    y0=0, y1=1, yref=\"paper\", x0=age_avg, x1=age_avg, xref=\"x\"\n",
    ")\n",
    "\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e9f88",
   "metadata": {},
   "source": [
    "#### Player Counting Of Each Teams And Positions ASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7aae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data_ASA, columns=['Team','Player','Position'])\n",
    "data_P = pd.get_dummies(new_data['Position'],prefix='Position')\n",
    "new_data = pd.concat([new_data, data_P],axis=1)\n",
    "group = new_data.groupby('Team')[['Position_CB','Position_CM','Position_DM','Position_FB','Position_GK','Position_ST','Position_W']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfff30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player Couting Of Each Teams and Positions (Dataset: ASA)\n",
    "\n",
    "trace0 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_CB,\n",
    "                name = \"Position_CB\",\n",
    "                marker = dict(color = 'rgb(102,255,255)')\n",
    "                )\n",
    "\n",
    "trace1 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_CM,\n",
    "                name = \"Position_CM\",\n",
    "                marker = dict(color = 'rgb(102,178,255)')\n",
    "                )\n",
    "\n",
    "trace2 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_DM,\n",
    "                name = \"Position_DM\",\n",
    "                marker = dict(color = 'rgb(102,102,255)')\n",
    "                )\n",
    "\n",
    "trace3 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_FB,\n",
    "                name = \"Position_FB\",\n",
    "                marker = dict(color = 'rgb(178, 102, 255)')\n",
    "                )\n",
    "\n",
    "trace4 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_GK,\n",
    "                name = \"Position_GK\",\n",
    "                marker = dict(color = 'rgb(255, 102, 255)')\n",
    "                )\n",
    "\n",
    "trace5 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_ST,\n",
    "                name = \"Position_ST\",\n",
    "                marker = dict(color = 'rgb(255, 255, 178)')\n",
    "                )\n",
    "\n",
    "trace6 = go.Bar(\n",
    "                x = group.index.values,\n",
    "                y = group.Position_W,\n",
    "                name = \"Position_W\",\n",
    "                marker = dict(color = 'rgb(173, 255, 43)')\n",
    "                )\n",
    "\n",
    "data = [trace0,trace1,trace2,trace3,trace4,trace5,trace6]\n",
    "\n",
    "layout = go.Layout(\n",
    "                   paper_bgcolor='rgb(243, 243, 243)',\n",
    "                   plot_bgcolor='rgb(243, 243, 243)',\n",
    "                   barmode = \"group\", \n",
    "                   title=\"Player Couting Of Each Teams and Positions\",\n",
    "                   xaxis= dict(title= 'Team',ticklen= 6,zeroline= False), \n",
    "                   yaxis= dict(title= 'Count of Players',ticklen= 6,zeroline= False))\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8079f64",
   "metadata": {},
   "source": [
    "#### Sum of Club Player and Sum of Market Value (Wy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1 = pd.DataFrame(data_Wy, columns=['Team within selected timeframe'])\n",
    "new_data1['Count Player'] = data_Wy.groupby('Team within selected timeframe')['Market value'].transform('count')\n",
    "new_data1['Sum Market Value'] = data_Wy.groupby('Team within selected timeframe')['Market value'].transform('sum')\n",
    "new_data1 = new_data1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_saving = [each for each in new_data1['Count Player']]\n",
    "y_net_worth  = [float(each) for each in new_data1['Sum Market Value']]\n",
    "x_saving = [each for each in new_data1['Team within selected timeframe']]\n",
    "x_net_worth  = [each for each in new_data1['Team within selected timeframe']]\n",
    "\n",
    "trace0 = go.Bar(\n",
    "                x=y_saving,\n",
    "                y=x_saving,\n",
    "                marker=dict(color='rgba(171, 50, 96, 0.6)',line=dict(color='rgba(171, 50, 96, 1.0)',width=1)),\n",
    "                name='Count Player',\n",
    "                orientation='h',\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "                x=y_net_worth,\n",
    "                y=x_net_worth,\n",
    "                mode='lines+markers',\n",
    "                line=dict(color='rgb(63, 72, 204)'),\n",
    "                name='Sum Market Value',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "                title='Sum of Club Player and Sum of Market Value',\n",
    "                yaxis=dict(showticklabels=True,domain=[0, 0.85]),\n",
    "                yaxis2=dict(showline=True,showticklabels=False,linecolor='rgba(102, 102, 102, 0.8)',linewidth=2,domain=[0, 0.85]),\n",
    "                xaxis=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0, 0.42]),\n",
    "                xaxis2=dict(zeroline=False,showline=False,showticklabels=True,showgrid=True,domain=[0.47, 1],side='top',dtick=1000000),\n",
    "                legend=dict(x=0.029,y=1.038,font=dict(size=10) ),\n",
    "                margin=dict(l=200, r=20,t=70,b=70),\n",
    "                paper_bgcolor='rgb(243, 243, 243)',\n",
    "                plot_bgcolor='rgb(243, 243, 243)'\n",
    ")\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=2, specs=[[{}, {}]], shared_xaxes=True,\n",
    "                          shared_yaxes=False, vertical_spacing=0.001)\n",
    "\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "\n",
    "fig['layout'].update(layout)\n",
    "py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f05746",
   "metadata": {},
   "source": [
    "#### Relation of All Player Minutes and Player Games ASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b803b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation of ALL Player Minutes and Player Games (Dataset: ASA)\n",
    "\n",
    "trace0 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'W'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'W'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of W\",\n",
    "                    marker = dict(color = 'blue'),\n",
    "                    text= data_ASA[data_ASA.Position == 'W'].Player)\n",
    "\n",
    "trace1 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'CM'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'CM'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of CM\",\n",
    "                    marker = dict(color = 'red'),\n",
    "                    text= data_ASA[data_ASA.Position == 'CM'].Player)\n",
    "\n",
    "trace2 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'CB'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'CB'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of CB\",\n",
    "                    marker = dict(color = 'rgba(255, 128, 255, 0.8)'),\n",
    "                    text= data_ASA[data_ASA.Position == 'CB'].Player)\n",
    "\n",
    "trace3 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'DM'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'DM'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of DM\",\n",
    "                    marker = dict(color = 'rgba(0, 255, 200, 0.8)'),\n",
    "                    text= data_ASA[data_ASA.Position == 'DM'].Player)\n",
    "\n",
    "trace4 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'FB'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'FB'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of FB\",\n",
    "                    marker = dict(color = 'rgba(255, 128, 2, 0.8)'),\n",
    "                    text= data_ASA[data_ASA.Position == 'FB'].Player)\n",
    "\n",
    "trace5 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'GK'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'GK'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of GK\",\n",
    "                    marker = dict(color = 'black'),\n",
    "                    text= data_ASA[data_ASA.Position == 'GK'].Player)\n",
    "\n",
    "trace6 =go.Scatter(\n",
    "                    x = data_ASA[data_ASA.Position == 'ST'].Minutes,\n",
    "                    y = data_ASA[data_ASA.Position == 'ST'].Games,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"Position of ST\",\n",
    "                    marker = dict(color = 'yellow'),\n",
    "                    text= data_ASA[data_ASA.Position == 'ST'].Player)\n",
    "\n",
    "data = [trace0,trace1,trace2,trace3,trace4,trace5,trace6]\n",
    "\n",
    "layout = dict(\n",
    "              paper_bgcolor='rgb(243, 243, 243)',\n",
    "              plot_bgcolor='rgb(243, 243, 243)',\n",
    "              title = 'Relation of Player Minutes and Player Games',\n",
    "              xaxis= dict(title= 'Minutes',ticklen= 6,gridcolor='rgb(255, 255, 255)',zeroline= False),\n",
    "              yaxis= dict(title= 'Games',ticklen= 6,gridcolor='rgb(255, 255, 255)',zeroline= False)\n",
    "             )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.offline.iplot(fig) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4b9c5",
   "metadata": {},
   "source": [
    "#### Country of birth statistics for foreign players (Wy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_data = data_Wy[['Birth country', 'Matches played']].copy().dropna()\n",
    "counter_data['Birth country'] = counter_data['Birth country'].replace(['Scotland', 'England', 'St. Kitts and Nevis', 'Tanzania',\n",
    "                                                                       'St. Vincent and the Grenadines','Republic of Ireland',\n",
    "                                                                       'Congo DR', 'Venezuela'],\n",
    "                                                                      ['United Kingdom of Great Britain and Northern Ireland',\n",
    "                                                                       'United Kingdom of Great Britain and Northern Ireland',\n",
    "                                                                      'Saint Kitts and Nevis', 'Tanzania, United Republic of',\n",
    "                                                                       'Saint Vincent and the Grenadines', 'Ireland',\n",
    "                                                                       'Congo, Democratic Republic of the',\n",
    "                                                                       'Venezuela (Bolivarian Republic of)'])\n",
    "\n",
    "#Counter\n",
    "counter_result = pd.DataFrame(columns = ['name', 'Totall matches played'])\n",
    "country_list = []\n",
    "count_cache = []\n",
    "for i in range(len(counter_data)):\n",
    "    if counter_data.iloc[i,0] not in country_list:\n",
    "        country_list.append(counter_data.iloc[i,0])\n",
    "        count_cache.append(counter_data.iloc[i,1])\n",
    "    else:\n",
    "        count_cache[country_list.index(counter_data.iloc[i,0])] += counter_data.iloc[i,1]\n",
    "\n",
    "counter_result['name'] = country_list\n",
    "counter_result['Totall matches played'] = count_cache\n",
    "counter_result = counter_result.sort_values(by = ['Totall matches played']).reset_index(drop=True)\n",
    "\n",
    "Three_letter_ISO = pd.read_csv(\"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\")\n",
    "\n",
    "#Merge two dataframe\n",
    "counter_result_ISO = pd.merge(counter_result, Three_letter_ISO[['name', 'alpha-3']].copy(), on='name')\n",
    "\n",
    "fig = px.choropleth(counter_result_ISO, locations=\"alpha-3\",\n",
    "                    color=\"Totall matches played\", # Totall matches played is a column of counter_result_ISO\n",
    "                    hover_name=\"Totall matches played\", # column to add to hover information\n",
    "                    color_continuous_scale=px.colors.sequential.Teal)\n",
    "fig.layout.update(title = 'Country of birth statistics for foreign players (Wy)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba6ee0",
   "metadata": {},
   "source": [
    "## 5. Features Selection (Wyscout Dataset) <a class=\"anchor\" id=\"sec_5\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Wy = pd.read_csv('datasets/Data_WyScout_Rating_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc33dbe",
   "metadata": {},
   "source": [
    "### 5.1 Split Dataset with Positions <a class=\"anchor\" id=\"sec_5.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f7abd",
   "metadata": {},
   "source": [
    "After discussing with Oakland Roots, we decide to select different features of each position.\n",
    "\n",
    "Description of colors (4):  \n",
    "<font color=red>The most important feature of the location</font>   \n",
    "<font color=blue>Important features of the location</font>   \n",
    "<font color=green>Universally important features</font>   \n",
    "Features with little reference value\n",
    "\n",
    "- FB: \n",
    "    - <font color=red>Successful defensive actions per 90</font>\n",
    "    - <font color=green> Passes per 90, Accurate passes %, Short/medium passes per 90, Accurate short/medium passes %</font>\n",
    "    - Goals, Non-penalty goals, Assists, Key passes per 90, Duels per 90, Duels won %, Shots blocked per 90, Interceptions per 90, Crosses per 90, Accurate crosses %, Crosses to goalie box per 90, Received passes per 90, Accurate long passes %, Shot assists per 90, Passes to final third per 90, Accurate passes to final third %\n",
    "\n",
    "- CB:\n",
    "    - <font color=red>Successful defensive actions per 90, Duels per 90, Duels won %, Accurate long passes %, Through passes per 90, Accurate through passes %</font>\n",
    "    - <font color=blue>Passes to final third per 90, Accurate passes to final third %, Dribbles per 90, Successful dribbles </font>\n",
    "    - <font color=green>Passes per 90, Accurate passes %, Short/medium passes per 90, Accurate short/medium passes %</font>\n",
    "    - Goals, Non-penalty goals, Assists, Shots blocked per 90, Interceptions per 90, Received passes per 90Key passes per 90\n",
    "    \n",
    "- CM:\n",
    "    - <font color=red>Aerial duels per 90, Touches in box per 90, Average pass length m</font>\n",
    "    - <font color=blue>Shot assists per 90, Passes to final third per 90, Accurate passes to final third %, Smart Pass per 90, Accurate smart passes %\n",
    "</font>\n",
    "    - <font color=green>Passes per 90, Accurate passes %, Short/medium passes per 90, Accurate short/medium passes %</font>\n",
    "    - Goals, Non-penalty goals, Assists, Duels per 90, Duels won %, Sliding tackles per 90, Interceptions per 90, Received passes per 90, PAdj Interceptions\n",
    "    \n",
    "- AM: \n",
    "    - <font color=red>Touches in box per 90, Forward passes per 90, Accurate forward passes %, Average pass length m, Second assists per 90</font>\n",
    "    - <font color=blue>Successful attacking actions per 90, Offensive duels won %, Shot assists per 90, Third assists per 90, Passes to final third per 90, Accurate passes to final third %, Passes to penalty area per 90, Accurate passes to penalty area %</font>\n",
    "    - <font color=green>Passes per 90, Accurate passes %, Short/medium passes per 90, Accurate short/medium passes %</font>\n",
    "    - Goals, Non-penalty goals, Assists, Duels per 90, Duels won %, Key passes per 90, Received passes per 90, Key passes per 90\n",
    "    \n",
    "- W: \n",
    "    - <font color=red>Goals, Non-penalty goals, Assists, Crosses per 90, Accurate crosses %, Crosses to goalie box per 9, Dribbles per 90, Successful dribbles %</font>\n",
    "    - <font color=blue>Successful attacking actions per 90, Offensive duels won %, Shot assists per 90, Key passes per 90</font>\n",
    "    - <font color=green>Passes per 90, Accurate passes %, Short / medium passes per 90, Accurate short / medium passes %</font>\n",
    "    - Key passes per 90, Duels per 90, Duels won %, Shots on target %, Goal conversion %, Received passes per 90, Passes to penalty area per 90, Accurate passes to penalty area %\n",
    "    \n",
    "- CF: \n",
    "    - <font color=red>Goals, Non-penalty goals, Shots on target %, Goal conversion %, Key passes per 90</font>\n",
    "    - <font color=blue>Aerial duels per 90, Aerial duels won %, Successful attacking actions per 90, Offensive duels won %,\n",
    "      Shot assists per 90</font>\n",
    "    - <font color=green>Passes per 90, Accurate passes %, Short / medium passes per 90, Accurate short / medium passes %</font>\n",
    "    - Assists, Pass%, Key passes per 90, Duels per 90, Duels won %, Touches in box per 90, Received passes per 90\n",
    "    \n",
    "- GK: \n",
    "    - <font color=red>Accurate short / medium passes %, Save rate %</font>\n",
    "    - <font color=blue>Short / medium passes per 90, Shots against</font>\n",
    "    - Long passes per 90, Accurate long passes %, Conceded goals per 90, Clean sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff6b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_FB = data_Wy[data_Wy['FB'] == 'FB']\n",
    "data_FB = data_FB[['Goals','Non-penalty goals','Assists','Key passes per 90','Successful defensive actions per 90',\n",
    "                   'Duels per 90','Duels won, %','Shots blocked per 90','Interceptions per 90','Crosses per 90',\n",
    "                   'Accurate crosses, %','Crosses to goalie box per 90','Received passes per 90','Passes per 90', \n",
    "                   'Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %', 'Accurate long passes, %',\n",
    "                   'Shot assists per 90','Passes to final third per 90','Accurate passes to final third, %','Rating']]\n",
    "data_CB = data_Wy[data_Wy['CB'] == 'CB']\n",
    "data_CB = data_CB[['Goals','Non-penalty goals','Assists','Key passes per 90','Successful defensive actions per 90',\n",
    "                   'Duels per 90','Duels won, %','Shots blocked per 90','Interceptions per 90','Received passes per 90',\n",
    "                   'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "                   'Accurate long passes, %','Passes to final third per 90','Accurate passes to final third, %',\n",
    "                   'Dribbles per 90','Successful dribbles, %','Through passes per 90','Accurate through passes, %','Rating']]\n",
    "data_CM = data_Wy[data_Wy['CM'] == 'CM']\n",
    "data_CM = data_CM[['Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Aerial duels per 90',\n",
    "                   'Touches in box per 90','Sliding tackles per 90','Interceptions per 90','Received passes per 90',\n",
    "                   'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "                   'Average pass length, m','Shot assists per 90','Passes to final third per 90','Accurate passes to final third, %',\n",
    "                   'PAdj Interceptions','Smart passes per 90','Accurate smart passes, %','Rating']]\n",
    "data_AM = data_Wy[data_Wy['AM'] == 'AM']\n",
    "data_AM = data_AM[['Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Key passes per 90',\n",
    "                   'Touches in box per 90','Successful attacking actions per 90','Offensive duels won, %','Received passes per 90',\n",
    "                   'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "                   'Forward passes per 90','Accurate forward passes, %','Average pass length, m','Shot assists per 90',\n",
    "                   'Second assists per 90','Third assists per 90','Passes to final third per 90',\n",
    "                   'Accurate passes to final third, %','Passes to penalty area per 90',\n",
    "                   'Accurate passes to penalty area, %','Rating']]\n",
    "data_W = data_Wy[data_Wy['W'] == 'W']\n",
    "data_W = data_W[['Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Shots on target, %',\n",
    "                 'Successful attacking actions per 90','Goal conversion, %','Crosses per 90',\n",
    "                 'Accurate crosses, %','Crosses to goalie box per 90','Offensive duels won, %','Received passes per 90',\n",
    "                 'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %', \n",
    "                 'Shot assists per 90','Key passes per 90','Passes to penalty area per 90','Accurate passes to penalty area, %',\n",
    "                 'Dribbles per 90','Successful dribbles, %','Rating']]\n",
    "data_CF = data_Wy[data_Wy['CF'] == 'CF']\n",
    "data_CF = data_CF[['Goals','Non-penalty goals','Assists','Aerial duels per 90',\n",
    "                   'Aerial duels won, %','Duels per 90','Duels won, %','Successful attacking actions per 90',\n",
    "                   'Shots on target, %','Goal conversion, %','Offensive duels won, %','Touches in box per 90',\n",
    "                   'Received passes per 90','Passes per 90','Accurate passes, %','Short / medium passes per 90',\n",
    "                   'Accurate short / medium passes, %','Shot assists per 90','Key passes per 90','Rating']]\n",
    "data_GK = data_Wy[data_Wy['GK'] == 'GK']\n",
    "data_GK = data_GK[['Short / medium passes per 90','Accurate short / medium passes, %','Long passes per 90',\n",
    "                   'Accurate long passes, %','Conceded goals per 90','Shots against','Clean sheets','Save rate, %', 'Rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ba6b9",
   "metadata": {},
   "source": [
    "### 5.2 Deploy Random Forest Algorithm <a class=\"anchor\" id=\"sec_5.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbf2a1",
   "metadata": {},
   "source": [
    "Using Random Forest Tree to rank the importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6324b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(data):\n",
    "    \n",
    "    data_copy = data.copy()\n",
    "    data_copy[\"Rating\"] = data_copy[\"Rating\"].astype(\"str\")\n",
    "    data_copy = data_copy.drop(data_copy[data_copy['Rating']=='-'].index)\n",
    "    Y = data_copy.iloc[:, [-1]]\n",
    "    Y.reset_index(drop=True,inplace=True)\n",
    "    X = data_copy.iloc[:, 0:-1]\n",
    "    X.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    # sort column index with number of nan value from smallest to largest\n",
    "    sortindex = np.argsort(X.isnull().sum(axis=0)).values\n",
    "    \n",
    "    for i in sortindex:\n",
    "        # set i column as target \n",
    "        feature_i = X.iloc[:, i]\n",
    "    \n",
    "        # set other columns as features, including 'y'\n",
    "        tmp_df = pd.concat([X.iloc[:, X.columns != i], Y], axis=1)\n",
    "    \n",
    "        # Fill remaining column missing values with 0\n",
    "        imp_mf = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "        tmp_df_mf = imp_mf.fit_transform(tmp_df)\n",
    "\n",
    "        # Use notnull samples in feature_i as training dataset\n",
    "        y_notnull = feature_i[feature_i.notnull()]\n",
    "        y_null = feature_i[feature_i.isnull()]   \n",
    "        X_notnull = tmp_df_mf[y_notnull.index, :]\n",
    "        X_null = tmp_df_mf[y_null.index, :] \n",
    "    \n",
    "        # continue if this column has no nan value\n",
    "        if y_null.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # RF Regression \n",
    "        rfc = RandomForestRegressor(n_estimators=100)\n",
    "        rfc = rfc.fit(X_notnull, y_notnull)\n",
    "    \n",
    "        # predict nan value\n",
    "        y_predict = rfc.predict(X_null)\n",
    "    \n",
    "        # fill\n",
    "        X.loc[X.iloc[:, i].isnull(), X.columns[i]] = y_predict\n",
    "        data_copy.loc[data_copy.iloc[:, i].isnull(), data_copy.columns[i]] = y_predict\n",
    "    \n",
    "    # split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "    \n",
    "    global selected_features, feat_lables\n",
    "    \n",
    "    feat_lables=data_copy.columns[1:]\n",
    "    \n",
    "    forest = RandomForestClassifier(oob_score=True, n_estimators=100, random_state=100, n_jobs=-1)\n",
    "    forest.fit(x_train, y_train)\n",
    "    \n",
    "    # select features which threshold larger then 0.025\n",
    "    selector = SelectFromModel(forest, threshold=0.025)\n",
    "    features_important = selector.fit_transform(x_train, y_train)\n",
    "    model = forest.fit(features_important, y_train)\n",
    "    selected_features = model.feature_importances_\n",
    "    \n",
    "    # print features\n",
    "    sorted_idx = np.argsort(selected_features)[::-1]\n",
    "    \n",
    "    for f in range(len(sorted_idx)):\n",
    "        print(\"%2d) %-*s %f\"%(f + 1,30,feat_lables[sorted_idx[f]],selected_features[sorted_idx [f]]))    \n",
    "    \n",
    "\n",
    "    data0 = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(sorted_idx)):\n",
    "        data0.insert(i, feat_lables[sorted_idx[i]], data_copy[feat_lables[sorted_idx[i]]], True)\n",
    "    \n",
    "    if 'Rating' in data0.columns:\n",
    "        data0.drop(['Rating'], axis=1, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b7967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "position_list = [data_FB, data_CB, data_CM, data_AM, data_W, data_CF, data_GK]\n",
    "position_name = ['FB', 'CB', 'CM', 'AM', 'W', 'CF', 'GK']\n",
    "model_name = [0, 1, 2, 3, 4, 5, 6]\n",
    "num = 0\n",
    "for i in position_list:\n",
    "    print('For position', position_name[num])\n",
    "    model_name[num] = RandomForest(i)\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        y = selected_features, x = feat_lables.values, mode='markers',\n",
    "        marker=dict(\n",
    "            sizemode = 'diameter', sizeref = 1, size = 25, color = selected_features, colorscale='Portland',showscale=True\n",
    "        ))\n",
    "    data = [trace]\n",
    "    layout= go.Layout(\n",
    "            paper_bgcolor='rgb(243, 243, 243)',\n",
    "            plot_bgcolor='rgb(243, 243, 243)',\n",
    "            autosize= True,\n",
    "            title= 'Random Forest Feature Importance',\n",
    "            hovermode= 'closest',\n",
    "            yaxis=dict(title= 'Feature Importance', ticklen= 5,gridwidth= 2),\n",
    "            showlegend= False\n",
    "        )\n",
    "    fig = go.Figure(data = data, layout = layout)\n",
    "    py.offline.iplot(fig) \n",
    "    \n",
    "    fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "    for j in model_name[num].columns[1:]:\n",
    "        if max(model_name[num][j]) < 5:\n",
    "            fig.add_trace((go.Box(y=model_name[num][j],name=j)),row=1, col=1)\n",
    "        elif 6 < max(model_name[num][j]) < 50:\n",
    "            fig.add_trace((go.Box(y=model_name[num][j],name=j)),row=2, col=1)\n",
    "        else:\n",
    "            fig.add_trace((go.Box(y=model_name[num][j],name=j)),row=3, col=1)\n",
    "            \n",
    "    updatemenus = list([dict(\n",
    "    type = \"buttons\", \n",
    "    direction = \"left\", \n",
    "    buttons=list([\n",
    "            dict(args = [\"type\", \"box\"], label = \"Box\", method = \"restyle\"),\n",
    "            dict(args = [\"type\", \"violin\"], label = \"Violin\", method = \"restyle\")]), \n",
    "    pad = {\"r\": 2, \"t\": 2},\n",
    "    showactive = True,\n",
    "    x = 0.01,\n",
    "    xanchor = \"left\",\n",
    "    y = 1.05,\n",
    "    yanchor = \"top\")])\n",
    "\n",
    "            \n",
    "    fig.layout.update(\n",
    "        go.Layout(\n",
    "        polar = dict(\n",
    "            radialaxis = dict(\n",
    "                visible = True,)),\n",
    "        showlegend = True,\n",
    "        title = 'Box and Violin Plot of Features',\n",
    "        updatemenus=updatemenus,\n",
    "        paper_bgcolor='rgb(243, 243, 243)',\n",
    "        plot_bgcolor='rgb(243, 243, 243)',\n",
    "        height=740\n",
    "        ))\n",
    "    \n",
    "    py.offline.iplot(fig)\n",
    "    \n",
    "    num += 1\n",
    "    \n",
    "data_FB_Selected = model_name[0]\n",
    "data_CB_Selected = model_name[1]\n",
    "data_CM_Selected = model_name[2]\n",
    "data_AM_Selected = model_name[3]\n",
    "data_W_Selected = model_name[4]\n",
    "data_CF_Selected = model_name[5]\n",
    "data_GK_Selected = model_name[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c0cae",
   "metadata": {},
   "source": [
    "## 6. Cosine Distance <a class=\"anchor\" id=\"sec_6\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10871d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Sample = pd.read_csv('datasets/Data_Sample.csv')\n",
    "data_Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine_Distance(Player_data, Position_data):\n",
    "    \n",
    "    data_copy = Position_data.copy()\n",
    "    # select player\n",
    "    name = data_Sample[data_Sample[\"Player\"] == Player_data]\n",
    "    # select features in data_sample dataset\n",
    "    feature = name[[i for i in data_copy.columns.tolist()]]\n",
    "    \n",
    "    # normalize\n",
    "    sclar = preprocessing.StandardScaler()\n",
    "    data_Norm = pd.DataFrame(sclar.fit_transform(pd.concat([feature, data_copy])))\n",
    "    \n",
    "    x = data_Norm.iloc[0:1]\n",
    "    y = data_Norm.iloc[1:]\n",
    "    \n",
    "    cos_s = []\n",
    "    cos_d = []\n",
    "    player = []\n",
    "   \n",
    "    # cos_sim & cos_dis\n",
    "    for i in range(len(y)):\n",
    "        simi = cosine_similarity(x, y[i:i+1]).tolist()[0][0]\n",
    "        cos_s.append(simi)\n",
    "        dist = paired_distances(x, y[i:i+1], metric='cosine').tolist()[0]\n",
    "        cos_d.append(dist)\n",
    "    \n",
    "    for i in Position_data.index:\n",
    "        player.append(data_Wy['Player'][i])\n",
    "        \n",
    "    data0 = data_copy\n",
    "    data0.loc[:, 'Cosine Similarity'] = cos_s\n",
    "    data0.loc[:, 'Cosine Distances'] = cos_d\n",
    "    data0.loc[:, 'Player'] = player\n",
    "    data0 = data0.sort_values(by=['Cosine Similarity'],axis=0,ascending=[False]) \n",
    "    \n",
    "    return data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1719b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_JSands = Cosine_Distance('J. Sands', data_CB_Selected)\n",
    "data_JSands.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RDamus = Cosine_Distance('R. Damus', data_CF_Selected)\n",
    "data_RDamus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RCannon = Cosine_Distance('R. Cannon', data_FB_Selected)\n",
    "data_RCannon.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f323588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_CBassett = Cosine_Distance('C. Bassett', data_CF_Selected)\n",
    "data_CBassett.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf2190",
   "metadata": {},
   "source": [
    "### 6.1 Radar Plot <a class=\"anchor\" id=\"sec_6.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Polar(Player_data, Selected_Player_data):\n",
    "    \n",
    "    data_copy = Selected_Player_data.copy().iloc[0:1,:-3]\n",
    "\n",
    "    # select player\n",
    "    name = data_Sample[data_Sample[\"Player\"] == Player_data]\n",
    "    # select features in data_sample dataset\n",
    "    feature = name[[i for i in data_copy.columns.tolist()]]\n",
    "    \n",
    "    data = pd.concat([feature, data_copy])\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2,specs=[[{\"type\": \"Polar\"},{\"type\": \"Polar\"}]])\n",
    "\n",
    "    R1=[]\n",
    "    theta1=[]\n",
    "    R2=[]\n",
    "    theta2=[]\n",
    "    R3=[]\n",
    "    theta3=[]\n",
    "    R4=[]\n",
    "    theta4=[]\n",
    "    \n",
    "    for i in data.columns[1:]:\n",
    "        \n",
    "        if max(data[i]) < 20:\n",
    "            R1.append(feature[i].iloc[0])\n",
    "            theta1.append(i)\n",
    "            R2.append(data_copy[i].iloc[0])\n",
    "            theta2.append(i)\n",
    "        else:   \n",
    "            R3.append(feature[i].iloc[0])\n",
    "            theta3.append(i)\n",
    "            R4.append(data_copy[i].iloc[0])\n",
    "            theta4.append(i)\n",
    "            \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r = R1,\n",
    "          theta = theta1,\n",
    "          fill = 'toself',\n",
    "          marker_color='rgb(47,138,196,30)',\n",
    "          name = Player_data,\n",
    "          ),row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r = R2,\n",
    "          theta = theta2,\n",
    "          fill = 'toself',\n",
    "          marker_color='rgb(229,210,245,0.2)',\n",
    "          name = Selected_Player_data.Player.values[0]),row=1, col=1)\n",
    "      \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r = R3,\n",
    "          theta = theta3,\n",
    "          fill = 'toself',\n",
    "          marker_color='rgb(47,138,196,30)',\n",
    "          name = Player_data),row=1, col=2)\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "          r = R4,\n",
    "          theta = theta4,\n",
    "          fill = 'toself',\n",
    "          marker_color='rgb(229,210,245,0.2)',\n",
    "          name = Selected_Player_data.Player.values[0]),row=1, col=2)\n",
    "\n",
    "    fig.layout.update(\n",
    "        go.Layout(\n",
    "        polar = dict(\n",
    "            radialaxis = dict(\n",
    "                visible = True,)),\n",
    "        showlegend = True,\n",
    "        title = \"{} vs {}\".format(Player_data, Selected_Player_data.Player.values[0]),\n",
    "        height=400, width=1300,\n",
    "        paper_bgcolor='rgb(243, 243, 243)',\n",
    "        plot_bgcolor='rgb(243, 243, 243)',\n",
    "        ))\n",
    "    \n",
    "    return py.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ede4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polar('J. Sands', data_JSands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polar('R. Damus', data_RDamus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polar('R. Cannon', data_RCannon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a202f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polar('C. Bassett', data_CBassett)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57718b2f",
   "metadata": {},
   "source": [
    "### 6.1.1 Player comparison engine <a class=\"anchor\" id=\"sec_6.1.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_selected_list = [data_FB_Selected, data_CB_Selected, data_CM_Selected, data_AM_Selected, data_W_Selected, data_CF_Selected, data_GK_Selected]\n",
    "position_name = ['FB', 'CB', 'CM', 'AM', 'W', 'CF', 'GK']\n",
    "playname_list = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "\n",
    "num = 0\n",
    "for i in position_selected_list:\n",
    "    player_name = []\n",
    "    for j in i.index:\n",
    "        player_name.append(data_Wy['Player'][j])\n",
    "    playname_list[num] = player_name\n",
    "    num += 1\n",
    "    \n",
    "Name_FB = playname_list[0]\n",
    "Name_CB = playname_list[1]\n",
    "Name_CM = playname_list[2]\n",
    "Name_AM = playname_list[3]\n",
    "Name_W = playname_list[4]\n",
    "Name_CF = playname_list[5]\n",
    "Name_GK = playname_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = JupyterDash(__name__)\n",
    "\n",
    "# app.layout = html.Div([\n",
    "#     dcc.Markdown('''\n",
    "#         #### Introduction\n",
    "#         This engine applies to the player ability comparison of `Data_WyScout_Rating_2021.csv`.\\n\n",
    "#         Before using it, you need to select the **type of position** you want to compare first.\\n\n",
    "#         Next, **select the names of the two players separately**. This engine supports search function.\\n\n",
    "#         Finally, click the **submit button** to generate the comparison chart.\\n\n",
    "#         The engine generates interactive images, which can be interacted with by mouse clicks.\\n\n",
    "#     '''),\n",
    "    \n",
    "#     html.Div([\n",
    "#         \"Position\",\n",
    "#         dcc.Dropdown(id=\"position_select\",\n",
    "#                      options = position_name,\n",
    "#                      placeholder = 'First step: select the position'\n",
    "#                     ),\n",
    "#     ]),\n",
    "#     html.Div([\n",
    "#         \"First player\",\n",
    "#         dcc.Dropdown(id=\"player1_select\",\n",
    "#                     placeholder = 'Second step: select the first player'\n",
    "#                     ),\n",
    "#     ]),\n",
    "#     html.Div([\n",
    "#         \"Second player\",\n",
    "#         dcc.Dropdown(id=\"player2_select\",\n",
    "#                     placeholder = 'Third step: select the second player'\n",
    "#                     ),\n",
    "#     ]),\n",
    "#     html.Button('Submit', id='submit-val', n_clicks=0),\n",
    "#     html.Div(id='container-button-basic',\n",
    "#              children='Complete the above three steps and press submit'),\n",
    "#     dcc.Graph(id='radar_plot')\n",
    "# ])\n",
    "\n",
    "# @app.callback(\n",
    "#     [Output(\"player1_select\", \"options\"),\n",
    "#      Output(\"player2_select\", \"options\")],\n",
    "#     Input(\"position_select\", \"value\")\n",
    "# )\n",
    "# def player_update(value):\n",
    "#     if not value:\n",
    "#         raise PreventUpdate\n",
    "#     elif value == 'FB':\n",
    "#         return Name_FB, Name_FB\n",
    "#     elif value == 'CB':\n",
    "#         return Name_CB, Name_CB\n",
    "#     elif value == 'CM':\n",
    "#         return Name_CM, Name_CM\n",
    "#     elif value == 'AM':\n",
    "#         return Name_AM, Name_AM\n",
    "#     elif value == 'W':\n",
    "#         return Name_W, Name_W\n",
    "#     elif value == 'CF':\n",
    "#         return Name_CF, Name_CF\n",
    "#     elif value == 'GK':\n",
    "#         return Name_GK, Name_GK\n",
    "    \n",
    "# @app.callback(\n",
    "#     [Output(\"radar_plot\", \"figure\"),\n",
    "#     Output(\"container-button-basic\", \"children\"),\n",
    "#     Output(\"submit-val\", \"n_clicks\")],\n",
    "#     [Input(\"player1_select\", \"value\"),\n",
    "#      Input(\"player2_select\", \"value\"),\n",
    "#      Input(\"position_select\", \"value\"),\n",
    "#     Input(\"submit-val\", \"n_clicks\")]\n",
    "# )\n",
    "# def Graph_update(Player1, Player2, Position, switch):\n",
    "#     if switch == 0:\n",
    "#         raise PreventUpdate\n",
    "#     elif not Player1:\n",
    "#         raise PreventUpdate\n",
    "#     elif not Player2:\n",
    "#         raise PreventUpdate\n",
    "#     elif not Position:\n",
    "#         raise PreventUpdate\n",
    "#     else:\n",
    "#         pass\n",
    "    \n",
    "#     if Position == 'FB':\n",
    "#         Position_data = data_FB_Selected\n",
    "#     elif Position == 'CB':\n",
    "#         Position_data = data_CB_Selected\n",
    "#     elif Position == 'CM':\n",
    "#         Position_data = data_CM_Selected\n",
    "#     elif Position == 'AM':\n",
    "#         Position_data = data_AM_Selected\n",
    "#     elif Position == 'W':\n",
    "#         Position_data = data_W_Selected\n",
    "#     elif Position == 'CF':\n",
    "#         Position_data = data_CF_Selected\n",
    "#     elif Position == 'GK':\n",
    "#         Position_data = data_GK_Selected\n",
    "    \n",
    "#     data_copy = Position_data.copy()\n",
    "    \n",
    "#     #Fill back players' name after feature selection\n",
    "#     player_name = []\n",
    "#     for i in Position_data.index:\n",
    "#         player_name.append(data_Wy['Player'][i])\n",
    "#     data_copy.loc[:, 'Player'] = player_name\n",
    "    \n",
    "#     #Positioning input player data and merge them into one dataframe in order to prepare for plot\n",
    "#     player1_data = data_copy[data_copy['Player'] == Player1].iloc[0:1,: -1]\n",
    "#     player2_data = data_copy[data_copy['Player'] == Player2].iloc[0:1,: -1]\n",
    "#     plot_data = pd.concat([player1_data, player2_data])\n",
    "    \n",
    "#     #Radar plot\n",
    "#     fig = make_subplots(rows=1, cols=2,specs=[[{\"type\": \"Polar\"},{\"type\": \"Polar\"}]])\n",
    "\n",
    "#     R1=[]\n",
    "#     theta1=[]\n",
    "#     R2=[]\n",
    "#     theta2=[]\n",
    "#     R3=[]\n",
    "#     theta3=[]\n",
    "#     R4=[]\n",
    "#     theta4=[]\n",
    "    \n",
    "#     for i in plot_data.columns:\n",
    "#         if max(plot_data[i]) < 20:\n",
    "#             R1.append(plot_data[i].iloc[0])\n",
    "#             theta1.append(i)\n",
    "#             R2.append(plot_data[i].iloc[1])\n",
    "#             theta2.append(i)\n",
    "#         else:   \n",
    "#             R3.append(plot_data[i].iloc[0])\n",
    "#             theta3.append(i)\n",
    "#             R4.append(plot_data[i].iloc[1])\n",
    "#             theta4.append(i)\n",
    "            \n",
    "#     fig.add_trace(go.Scatterpolar(\n",
    "#           r = R1,\n",
    "#           theta = theta1,\n",
    "#           fill = 'toself',\n",
    "#           marker_color='rgb(47,138,196,30)',\n",
    "#           name = Player1),row=1, col=1)\n",
    "    \n",
    "#     fig.add_trace(go.Scatterpolar(\n",
    "#           r = R2,\n",
    "#           theta = theta2,\n",
    "#           fill = 'toself',\n",
    "#           marker_color='rgb(229,210,245,0.2)',\n",
    "#           name = Player2),row=1, col=1)\n",
    "    \n",
    "#     fig.add_trace(go.Scatterpolar(\n",
    "#           r = R3,\n",
    "#           theta = theta3,\n",
    "#           fill = 'toself',\n",
    "#           marker_color='rgb(47,138,196,30)',\n",
    "#           name = Player1),row=1, col=2)\n",
    "    \n",
    "#     fig.add_trace(go.Scatterpolar(\n",
    "#           r = R4,\n",
    "#           theta = theta4,\n",
    "#           fill = 'toself',\n",
    "#           marker_color='rgb(229,210,245,0.2)',\n",
    "#           name = Player2),row=1, col=2)\n",
    "\n",
    "#     fig.layout.update(\n",
    "#         go.Layout(\n",
    "#         polar = dict(\n",
    "#             radialaxis = dict(\n",
    "#                 visible = True,)),\n",
    "#         showlegend = True,\n",
    "#         title = \"{} vs {}\".format(Player1, Player2),\n",
    "#         height=400, width=1200,\n",
    "#         paper_bgcolor='rgb(243, 243, 243)',\n",
    "#         plot_bgcolor='rgb(243, 243, 243)',\n",
    "#         ))\n",
    "    \n",
    "#     children = 'Data confirm, graph generated.'\n",
    "#     switch = 0\n",
    "#     return fig, children, switch\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298908fe",
   "metadata": {},
   "source": [
    "### 6.2 Another Way Cosine Distance <a class=\"anchor\" id=\"sec_6.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ed7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('datasets/Data_Sample.csv')\n",
    "\n",
    "# Position rearrangement\n",
    "sample['FB'] = ['FB' if len(set(i.replace(' ','').split(',')) & set(FB))>0 else ''  for i in sample['Position']]\n",
    "sample['CB'] = ['CB' if len(set(i.replace(' ','').split(',')) & set(CB))>0 else ''  for i in sample['Position']]\n",
    "sample['CM'] = ['CM' if len(set(i.replace(' ','').split(',')) & set(CM))>0 else ''  for i in sample['Position']]\n",
    "sample['AM'] = ['AM' if len(set(i.replace(' ','').split(',')) & set(AM))>0 else ''  for i in sample['Position']]\n",
    "sample['W'] = ['W' if len(set(i.replace(' ','').split(',')) & set(W))>0 else ''  for i in sample['Position']]\n",
    "sample['CF'] = ['CF' if len(set(i.replace(' ','').split(',')) & set(CF))>0 else ''  for i in sample['Position']]\n",
    "sample['GK'] = ['GK' if len(set(i.replace(' ','').split(',')) & set(GK))>0 else ''  for i in sample['Position']]\n",
    "\n",
    "# Categorization and merging\n",
    "sample['Position'] = [\",\".join([s for s in [sample['FB'][i],sample['CB'][i],sample['CM'][i],sample['AM'][i],\\\n",
    "                                    sample['W'][i],sample['CF'][i],sample['GK'][i]] if s !='']) for i in range(len(sample['Position']))]\n",
    "# Convert the units of Market value to USD\n",
    "sample['Market value'] = [i*1.07 for i in sample['Market value']]\n",
    "\n",
    "sample.to_csv('datasets/new/sample_new.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085943e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wy_rating_2021 = pd.read_csv('datasets/Data_WyScout_Rating_2021.csv')\n",
    "\n",
    "data_FB = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'FB']\n",
    "data_CB = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'CB']\n",
    "data_CM = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'CM']\n",
    "data_AM = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'AM']\n",
    "data_W = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'W']\n",
    "data_CF = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'CF']\n",
    "data_GK = data_wy_rating_2021[data_wy_rating_2021['Position'] == 'GK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data_wy_rating_2021.columns.drop(['FB','CB','CM','AM','W','CF','GK','Position','Player','Team','Team within selected timeframe','Market value','Contract expires','Birth country','Passport country','Foot','On loan','Rating'])\n",
    "\n",
    "# Outlier Fill (mean)\n",
    "rating_avg = round(data_wy_rating_2021['Rating'][data_wy_rating_2021['Rating']!='-'].astype('float').mean(),1)\n",
    "data_wy_rating_2021['Rating'].replace('-',6.6,inplace = True)\n",
    "data_wy_rating_2021['Rating'] = data_wy_rating_2021['Rating'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "features['FB'] = ['Assists','Passes per 90','Shots blocked per 90','Shot assists per 90','Successful defensive actions per 90','Crosses per 90','Short / medium passes per 90',\n",
    "'Crosses to goalie box per 90','Key passes per 90','Duels per 90','Accurate long passes, %','Interceptions per 90','Accurate passes, %','Received passes per 90',\n",
    "'Passes to final third per 90','Duels won, %','Accurate crosses, %','Accurate short / medium passes, %','Non-penalty goals']\n",
    "\n",
    "features['CB'] = ['Short / medium passes per 90','Accurate long passes, %','Key passes per 90','Assists','Passes per 90','Successful defensive actions per 90','Interceptions per 90',\n",
    "'Accurate short / medium passes, %','Shots blocked per 90','Received passes per 90','Dribbles per 90','Passes to final third per 90','Duels won, %',\n",
    "'Non-penalty goals','Duels per 90','Accurate passes to final third, %','Accurate passes, %','Successful dribbles, %']\n",
    "\n",
    "features['CM'] = ['Accurate short / medium passes, %','Sliding tackles per 90','Aerial duels per 90','Passes to final third per 90','Accurate passes, %','Average pass length, m',\n",
    "'Passes per 90','Accurate passes to final third, %','Duels won, %','Duels per 90','PAdj Interceptions','Short / medium passes per 90','Received passes per 90',\n",
    "'Shot assists per 90','Interceptions per 90','Assists','Touches in box per 90','Smart passes per 90','Non-penalty goals']\n",
    "\n",
    "features['AM'] = ['Passes to penalty area per 90','Received passes per 90','Passes to final third per 90','Accurate short / medium passes, %','Accurate forward passes, %',\n",
    "'Forward passes per 90','Short / medium passes per 90','Third assists per 90','Duels won, %','Accurate passes to final third, %','Touches in box per 90',\n",
    "'Accurate passes, %','Offensive duels won, %','Shot assists per 90','Second assists per 90','Passes per 90','Average pass length, m','Non-penalty goals',\n",
    "'Successful attacking actions per 90','Key passes per 90','Assists','Duels per 90']\n",
    "\n",
    "features['W'] = ['Accurate passes, %','Short / medium passes per 90','Offensive duels won, %','Shots on target, %','Accurate passes to penalty area, %','Accurate short / medium passes, %',\n",
    "'Crosses per 90','Accurate crosses, %','Dribbles per 90','Passes per 90','Received passes per 90','Assists','Successful dribbles, %','Crosses to goalie box per 90',\n",
    "'Duels won, %','Passes to penalty area per 90','Duels per 90','Goal conversion, %','Non-penalty goals','Shot assists per 90','Successful attacking actions per 90','Key passes per 90']\n",
    "\n",
    "features['CF'] = ['Touches in box per 90','Shot assists per 90','Goal conversion, %','Successful attacking actions per 90','Short / medium passes per 90','Key passes per 90',\n",
    "'Shots on target, %','Received passes per 90','Aerial duels won, %','Passes per 90','Duels per 90','Duels won, %','Offensive duels won, %',\n",
    "'Non-penalty goals','Accurate short / medium passes, %','Assists','Accurate passes, %','Aerial duels per 90']\n",
    "\n",
    "features['GK'] = ['Conceded goals per 90','Clean sheets','Long passes per 90','Save rate, %','Accurate long passes, %','Accurate short / medium passes, %','Shots against']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d312d",
   "metadata": {},
   "source": [
    "#### 6.2.1 Position FB -- Most similar players to R. Cannon <a class=\"anchor\" id=\"sec_6.2.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38369e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB\n",
    "x = data_FB[features['FB']].fillna(-1)\n",
    "y = sample[features['FB']][sample['Player'] == 'R. Cannon'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_FB['Player'],'simi':list(simi[:,0])})\n",
    "FB_Player = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to R. Cannon - FB:',FB_Player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03317153",
   "metadata": {},
   "source": [
    "#### 6.2.2 Position CB -- Most similar players to J. Sands <a class=\"anchor\" id=\"sec_6.2.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CB\n",
    "x = data_CB[features['CB']].fillna(-1)\n",
    "y = sample[features['CB']][sample['Player'] == 'J. Sands'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_CB['Player'],'simi':list(simi[:,0])})\n",
    "CB_Player = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to J. Sands - CB:',CB_Player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2872250",
   "metadata": {},
   "source": [
    "#### 6.2.3 Position CM -- Most similar players to J. Sands & C. Bassett <a class=\"anchor\" id=\"sec_6.2.3\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306fc3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM\n",
    "# 2-1\n",
    "x = data_CM[features['CM']].fillna(-1)\n",
    "y = sample[features['CM']][sample['Player'] == 'J. Sands'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_CM['Player'],'simi':list(simi[:,0])})\n",
    "CM_Player_01 = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to J. Sands - CM:',CM_Player_01)\n",
    "\n",
    "\n",
    "# 2-2\n",
    "x = data_CM[features['CM']].fillna(-1)\n",
    "y = sample[features['CM']][sample['Player'] == 'C. Bassett'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_CM['Player'],'simi':list(simi[:,0])})\n",
    "CM_Player_02 = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to C. Bassett - CM:',CM_Player_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4398b",
   "metadata": {},
   "source": [
    "#### 6.2.4 Position AM -- Most similar players to C. Bassett <a class=\"anchor\" id=\"sec_6.2.4\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM\n",
    "x = data_AM[features['AM']].fillna(-1)\n",
    "y = sample[features['AM']][sample['Player'] == 'C. Bassett'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_AM['Player'],'simi':list(simi[:,0])})\n",
    "AM_Player = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to C. Bassett - AM:',AM_Player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b29f85",
   "metadata": {},
   "source": [
    "#### 6.2.5 Position CF -- Most similar players to R. Damus & C. Bassett <a class=\"anchor\" id=\"sec_6.2.5\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9215e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CF\n",
    "x = data_CF[features['CF']].fillna(-1)\n",
    "y = sample[features['CF']][sample['Player'] == 'R. Damus'].fillna(-1)\n",
    "\n",
    "# 2-1\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_CF['Player'],'simi':list(simi[:,0])})\n",
    "CF_Player_01 = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to R. Damus - CF:',CF_Player_01)\n",
    "\n",
    "# 2-2\n",
    "y = sample[features['CF']][sample['Player'] == 'C. Bassett'].fillna(-1)\n",
    "\n",
    "# Similarity calculation\n",
    "simi = cosine_similarity(x, y)\n",
    "simi_data = pd.DataFrame({'Player':data_CF['Player'],'simi':list(simi[:,0])})\n",
    "CF_Player_02 = list(simi_data.sort_values('simi',ascending=False).head(5)['Player'])\n",
    "print('Most similar players to C. Bassett - CF:',CF_Player_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17b031",
   "metadata": {},
   "source": [
    "#### 6.2.6 Summary <a class=\"anchor\" id=\"sec_6.2.6\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7064bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_simi_player = pd.DataFrame({'Most similar players to R. Cannon - FB:':FB_Player,'Most similar players to J. Sands - CB:':CB_Player,'Most similar players to J. Sands - CM:':CM_Player_01,'Most similar players to C. Bassett - CM:':CM_Player_02,\n",
    " 'Most similar players to C. Bassett - AM:':AM_Player,'Most similar players to R. Damus - CF:':CF_Player_01,'Most similar players to C. Bassett - CF:':CF_Player_02})\n",
    "\n",
    "data_simi_player.to_csv('datasets/new/data_simi_player.csv',index = 0)\n",
    "data_simi_player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb61aaa",
   "metadata": {},
   "source": [
    "#### 6.2.7 Find Player Information <a class=\"anchor\" id=\"sec_6.2.7\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3998483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TansferMarkt_2021_new = pd.read_csv('datasets/new/data_TansferMarkt_2021_new.csv')\n",
    "index = re.compile(r\"[A-Z]\")\n",
    "data_TansferMarkt_2021_new['Player'] = [index.findall(\" \".join(i.split(' ')[:-1]))[-1] + '.' + ' ' + i.split(' ')[-1] if len(i.split(' '))>1 else i for i in data_TansferMarkt_2021_new['Player Name']]\n",
    "\n",
    "features_Wy = ['Player','Position','Contract expires','Team','Team within selected timeframe','Age','Birth country',\n",
    "               'Passport country','Foot','Market value']\n",
    "features_TM = ['Salary', 'Salary Date', 'Highest Market Value', 'Date of Highest Value',\n",
    "              'Joined Date', 'Contract Until', 'Date of Last Contract Extension', 'Player Agent',\n",
    "              'Player Name', 'Nat.', 'Age', 'Club', 'Position Detail', 'player_href']\n",
    "\n",
    "data_simi_player = pd.DataFrame({'Position':['FB']*5+['CB']*5+['CM']*10+['AM']*5+['CF']*10,\n",
    "                               'Player':FB_Player+CB_Player+CM_Player_01+CM_Player_02+AM_Player+CF_Player_01+CF_Player_02})\n",
    "\n",
    "tmp = data_Wy[features_Wy]\n",
    "tmp.columns = ['Player'] + ['Wy_'+i for i in tmp.columns.drop('Player')]\n",
    "\n",
    "tmp02 = data_TansferMarkt_2021_new[['Player'] + features_TM]\n",
    "tmp02.columns = ['Player'] + ['TM_'+i for i in features_TM]\n",
    "\n",
    "data_simi_player = data_simi_player.merge(tmp,on = ['Player'], how = 'left')\n",
    "data_simi_player = data_simi_player.merge(tmp02,on = ['Player'], how = 'left')\n",
    "data_simi_player.to_csv('datasets/results/Cosin_Distance_Player.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1588803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_simi_player.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11568c06",
   "metadata": {},
   "source": [
    "## 7. Rating Model <a class=\"anchor\" id=\"sec_7\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c52ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020 = pd.read_csv('datasets/new/Data_Wy_2020_new.csv')\n",
    "Data_Wy_2021 = pd.read_csv('datasets/new/Data_Wy_2021_new.csv')\n",
    "Data_SofaScore_2020 = pd.read_csv('datasets/Data_SofaScore_2020.csv')\n",
    "Data_SofaScore_2021 = pd.read_csv('datasets/Data_SofaScore_2021.csv')\n",
    "\n",
    "index = re.compile(r\"[A-Z]\")\n",
    "Data_SofaScore_2020['Player'] = [index.findall(\" \".join(i.split(' ')[:-1]))[-1] + '.' + ' ' + i.split(' ')[-1] if len(i.split(' '))>1 else i for i in Data_SofaScore_2020['Player']]\n",
    "Data_SofaScore_2021['Player'] = [index.findall(\" \".join(i.split(' ')[:-1]))[-1] + '.' + ' ' + i.split(' ')[-1] if len(i.split(' '))>1 else i for i in Data_SofaScore_2021['Player']]\n",
    "\n",
    "Data_Wy_2020 = Data_Wy_2020.merge(Data_SofaScore_2020[['Player','Rating']], on = ['Player'], how = 'inner')\n",
    "Data_Wy_2021 = Data_Wy_2021.merge(Data_SofaScore_2021[['Player','Rating']], on = ['Player'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['FB','CB','CM','AM','W','CF','GK']:\n",
    "    # samples from positions\n",
    "    data_tmp = Data_Wy_2020[Data_Wy_2020['Position'].fillna('').str.contains(p)] \n",
    "    \n",
    "    # training model\n",
    "    X = data_tmp[features[p]].fillna(-1)\n",
    "    Y = data_tmp['Rating']\n",
    "    forest=RandomForestRegressor(\n",
    "        criterion='mse', max_depth=4, min_samples_split=2, min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0, max_features='auto', random_state=0\n",
    "    )\n",
    "    forest.fit(X,Y)\n",
    "    \n",
    "    # 2021 predictions\n",
    "    # use positions to choose players\n",
    "    data_21 = Data_Wy_2021[Data_Wy_2021['Position'].fillna('').str.contains(p)]\n",
    "    # fill in nan\n",
    "    data_21['Rating_predict'] = forest.predict(data_21[features[p]].fillna(-1))\n",
    "    data_21['Rating_diff'] = data_21['Rating_predict'] - data_21['Rating'] #差值，判断标准\n",
    "    \n",
    "\n",
    "    # personal info features\n",
    "    data_21_01 = data_21[features_Wy + ['Rating','Rating_predict','Rating_diff']]\n",
    "    data_21_01.columns = ['Player'] + ['Wy_'+ i for i in data_21_01.columns.drop('Player')]\n",
    "    \n",
    "    data_21_02 = data_TansferMarkt_2021_new[['Player'] + features_TM]\n",
    "    data_21_02.columns = ['Player'] + ['TM_'+ i for i in features_TM]\n",
    "    \n",
    "    data_21 = data_21_01.merge(data_21_02,on = ['Player'], how = 'left')\n",
    "    \n",
    "    # save data for prediction\n",
    "    data_21.to_csv('datasets/new/data_wy_rating_2021_'+ p +'.csv',index = 0)\n",
    "    \n",
    "    # prediction value, true value is positive? top5 in descending order\n",
    "    data_21_top5 = data_21.sort_values('Wy_Rating_diff',ascending = False)\n",
    "    data_21_top5 = data_21_top5[data_21_top5['Wy_Rating']>0].head(5)\n",
    "    data_21_top5.to_csv('datasets/results/Top5_rating_2021_' + p +'.csv',index = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b858932",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating_result = pd.DataFrame()\n",
    "for p in ['FB','CB','CM','AM','W','CF','GK']:\n",
    "    Rating_top_5 = pd.read_csv('datasets/results/Top5_rating_2021_' + p +'.csv')\n",
    "    Rating_result = pd.concat([Rating_result,Rating_top_5],axis = 0)\n",
    "Rating_result.to_csv('datasets/results/Rating_Model_Players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613827c",
   "metadata": {},
   "source": [
    "## 8. Market Value Model <a class=\"anchor\" id=\"sec_8\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be32cc",
   "metadata": {},
   "source": [
    "### 8.1 Market Value Forecast <a class=\"anchor\" id=\"sec_8.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95694cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Wy_2020 = pd.read_csv('datasets/new/Data_Wy_2020_new.csv')\n",
    "Data_Wy_2021 = pd.read_csv('datasets/new/Data_Wy_2021_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['FB','CB','CM','AM','W','CF','GK']:\n",
    "    \n",
    "    # Sample by position of players in 2020\n",
    "    data_tmp = Data_Wy_2020[Data_Wy_2020['Position'].fillna('').str.contains(p)] \n",
    "    \n",
    "    # train model\n",
    "    X = data_tmp[all_features].fillna(-1)\n",
    "    Y = data_tmp['Market value']\n",
    "    \n",
    "    forest=RandomForestRegressor(\n",
    "        criterion='mse', max_depth=2, min_samples_split=2, min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0, max_features='auto', random_state=10)\n",
    "    \n",
    "    forest.fit(X,Y)\n",
    "    \n",
    "    # predict 2021\n",
    "    data_21 = Data_Wy_2021[Data_Wy_2021['Position'].fillna('').str.contains(p)]\n",
    "    data_21['Market_value_predict'] = forest.predict(data_21[all_features].fillna(-1))   # fill na\n",
    "    data_21['Market_value_diff'] = data_21['Market_value_predict'] - data_21['Market value']   # Judgment criteria, predicted value - true value\n",
    "    \n",
    "    # save information\n",
    "    data_21_01 = data_21[features_Wy + ['Market_value_predict','Market_value_diff']]\n",
    "    data_21_01.columns = ['Player'] + ['Wy_' + i for i in data_21_01.columns.drop('Player')] \n",
    "    \n",
    "    data_21_02 = data_TansferMarkt_2021_new[['Player']+features_TM]\n",
    "    data_21_02.columns = ['Player'] + ['TM_' + i for i in features_TM]\n",
    "    \n",
    "    data_21 = data_21_01.merge(data_21_02,on = ['Player'], how = 'left')\n",
    "    \n",
    "    # save prediction\n",
    "    data_21.to_csv('datasets/results/data_Market_value_2021_' + p +'.csv',index = 0)\n",
    "    \n",
    "    # If the predicted value - true value is positive, the top 5 will be ranked in descending order\n",
    "    data_21_top5 = data_21.sort_values('Wy_Market_value_diff', ascending = False)\n",
    "    data_21_top5 = data_21_top5[data_21_top5['Wy_Market value']>0].head(5)\n",
    "    data_21_top5.to_csv('datasets/results/Top5_Market_value_2021_' + p +'.csv',index = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f8e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MV_result = pd.DataFrame()\n",
    "for p in ['FB','CB','CM','AM','W','CF','GK']:\n",
    "    MV_top_5 = pd.read_csv('datasets/results/Top5_Market_value_2021_' + p +'.csv')\n",
    "    MV_result = pd.concat([MV_result,MV_top_5],axis = 0)\n",
    "MV_result.to_csv('datasets/results/Market_value_Model_Players.csv')\n",
    "MV_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e052c7",
   "metadata": {},
   "source": [
    "### 8.2 Market Value supplement <a class=\"anchor\" id=\"sec_8.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded048f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/new/Data_Wy_2021_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "Position_dict = {\n",
    "    'FB': {'Goals','Non-penalty goals','Assists','Key passes per 90','Successful defensive actions per 90',\n",
    "           'Duels per 90','Duels won, %','Shots blocked per 90','Interceptions per 90','Crosses per 90',\n",
    "           'Accurate crosses, %','Crosses to goalie box per 90','Received passes per 90','Passes per 90', \n",
    "           'Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %', 'Accurate long passes, %',\n",
    "           'Shot assists per 90','Passes to final third per 90','Accurate passes to final third, %'},\n",
    "    'CB': {'Goals','Non-penalty goals','Assists','Key passes per 90','Successful defensive actions per 90',\n",
    "           'Duels per 90','Duels won, %','Shots blocked per 90','Interceptions per 90','Received passes per 90',\n",
    "           'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "           'Accurate long passes, %','Passes to final third per 90','Accurate passes to final third, %',\n",
    "           'Dribbles per 90','Successful dribbles, %','Through passes per 90','Accurate through passes, %'},\n",
    "    'CM': {'Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Aerial duels per 90',\n",
    "           'Touches in box per 90','Sliding tackles per 90','Interceptions per 90','Received passes per 90',\n",
    "           'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "           'Average pass length, m','Shot assists per 90','Passes to final third per 90','Accurate passes to final third, %',\n",
    "           'PAdj Interceptions','Smart passes per 90','Accurate smart passes, %'},\n",
    "    'AM': {'Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Key passes per 90',\n",
    "           'Touches in box per 90','Successful attacking actions per 90','Offensive duels won, %','Received passes per 90',\n",
    "           'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %',\n",
    "           'Forward passes per 90','Accurate forward passes, %','Average pass length, m','Shot assists per 90',\n",
    "           'Second assists per 90','Third assists per 90','Passes to final third per 90',\n",
    "           'Accurate passes to final third, %','Passes to penalty area per 90',\n",
    "           'Accurate passes to penalty area, %'},\n",
    "    'W': {'Goals','Non-penalty goals','Assists','Duels per 90','Duels won, %','Shots on target, %',\n",
    "          'Successful attacking actions per 90','Goal conversion, %','Crosses per 90',\n",
    "          'Accurate crosses, %','Crosses to goalie box per 90','Offensive duels won, %','Received passes per 90',\n",
    "          'Passes per 90','Accurate passes, %','Short / medium passes per 90','Accurate short / medium passes, %', \n",
    "          'Shot assists per 90','Key passes per 90','Passes to penalty area per 90','Accurate passes to penalty area, %',\n",
    "          'Dribbles per 90','Successful dribbles, %'},\n",
    "    'CF': {'Goals','Non-penalty goals','Assists','Aerial duels per 90',\n",
    "           'Aerial duels won, %','Duels per 90','Duels won, %','Successful attacking actions per 90',\n",
    "           'Shots on target, %','Goal conversion, %','Offensive duels won, %','Touches in box per 90',\n",
    "           'Received passes per 90','Passes per 90','Accurate passes, %','Short / medium passes per 90',\n",
    "           'Accurate short / medium passes, %','Shot assists per 90','Key passes per 90'},\n",
    "    'GK': {'Short / medium passes per 90','Accurate short / medium passes, %','Long passes per 90',\n",
    "           'Accurate long passes, %','Conceded goals per 90','Shots against','Clean sheets','Save rate, %'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3299ea6",
   "metadata": {},
   "source": [
    "#### 8.2.1 Before supplement <a class=\"anchor\" id=\"sec_8.2.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_FB = data[data['FB'] == 'FB']\n",
    "data_FB_test = data_FB[data_FB['Market value'] == 0]\n",
    "data_FB_test[['Player', 'Market value']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = [0,1,2,3,4,5,6]\n",
    "num = 0\n",
    "for position,content in Position_dict.items():\n",
    "    #data preperarion\n",
    "    data_position = data[data[position] == position]\n",
    "    data_position_train = data_position[data_position['Market value'] != 0]\n",
    "    data_position_test = data_position[data_position['Market value'] == 0]\n",
    "    \n",
    "    data_position_train_x = data_position_train[content]\n",
    "    data_position_train_y = data_position_train[['Market value']]\n",
    "    \n",
    "    data_position_test_x = data_position_test[content]\n",
    "    \n",
    "    data_position_train_x = data_position_train_x.fillna(value=0)\n",
    "    data_position_test_x = data_position_test_x.fillna(value=0)\n",
    "    \n",
    "    \n",
    "    #Modeling and forecasting\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=30, random_state=2)\n",
    "    knn = KNeighborsRegressor(n_neighbors=20, weights='distance', algorithm='auto', p=2)\n",
    "    dt = DecisionTreeClassifier(criterion = 'entropy')\n",
    "    \n",
    "    rf.fit(data_position_train_x,data_position_train_y)\n",
    "    knn.fit(data_position_train_x,data_position_train_y)\n",
    "    dt.fit(data_position_train_x,data_position_train_y)\n",
    "    \n",
    "    positon_pr_rf = rf.predict(data_position_test_x)\n",
    "    positon_pr_knn = knn.predict(data_position_test_x)\n",
    "    positon_pr_dt = dt.predict(data_position_test_x)\n",
    "    \n",
    "    \n",
    "    #Data operation and backfill\n",
    "    positon_pr_knn = positon_pr_knn.reshape(len(positon_pr_knn))\n",
    "    value = np.sum([positon_pr_rf,positon_pr_knn,positon_pr_dt],axis = 0)/3\n",
    "    data_position_test['Market value'] = value\n",
    "    \n",
    "    cache[num] = data_position_test\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894cd402",
   "metadata": {},
   "source": [
    "#### 8.2.2 After supplement <a class=\"anchor\" id=\"sec_8.2.2\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5602118",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[0][['Player', 'Market value']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902096e2",
   "metadata": {},
   "source": [
    "### 9. Abandon cases <a class=\"anchor\" id=\"sec_9\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da9281",
   "metadata": {},
   "source": [
    "#### 9.1 The Neural Network Model to Predict the Market Value <a class=\"anchor\" id=\"sec_9.1\"></a>\n",
    "* [Back to menu](#sec_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b65a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/new/Data_Wy_2020_new.csv')\n",
    "\n",
    "#Screening out Categorical Features\n",
    "object_cols = [i for i in data.columns if data.dtypes[i]=='object']\n",
    "\n",
    "data_position = data[data['FB'] == 'FB']\n",
    "#Trop Categorical Features\n",
    "data_position = data_position.drop(columns=object_cols)\n",
    "data_position = data_position.astype('float')\n",
    "\n",
    "#Drop the data that have more than .3 null\n",
    "drop_df = data_position.loc[:, data_position.isnull().mean() < .3]\n",
    "\n",
    "#Fill na with column median\n",
    "for col in drop_df:\n",
    "    drop_df.loc[:, col] = drop_df.loc[:, col].fillna(drop_df[col].median())\n",
    "    \n",
    "#Normalizing\n",
    "drop_df.loc[:, drop_df.columns!=\"Market value\"] -= drop_df.loc[:, drop_df.columns!=\"Market value\"].mean()\n",
    "drop_df.loc[:, drop_df.columns!=\"Market value\"] /= drop_df.loc[:, drop_df.columns!=\"Market value\"].std()\n",
    "    \n",
    "#Split the train data and test data\n",
    "data_train = drop_df[drop_df['Market value'] != 0]\n",
    "data_test = drop_df[drop_df['Market value'] == 0]\n",
    "\n",
    "feature_train = data_train.copy().drop(columns=['Market value'])\n",
    "feature_test = data_train.copy()['Market value']\n",
    "\n",
    "#Feature Selection - Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 100, random_state=123)\n",
    "rf.fit(feature_train, feature_test)\n",
    "\n",
    "#Select important features\n",
    "feature_rankings = pd.DataFrame(rf.feature_importances_, columns = ['importance']).sort_values('importance', ascending=False)\n",
    "select = SelectFromModel(rf, threshold = 0.01)\n",
    "select.fit(feature_train, feature_test)\n",
    "selected_features = []\n",
    "for important_features in select.get_support(indices=True):\n",
    "    selected_features.append(feature_train.columns[important_features])\n",
    "    \n",
    "selected_features_plus = selected_features\n",
    "selected_features_plus.append(\"Market value\")\n",
    "data_train = data_train[selected_features_plus]\n",
    "\n",
    "#Train/Test Split the train data\n",
    "X_train = data_train.loc[:data_train.shape[0]*4//5, data_train.columns!=\"Market value\"]\n",
    "X_test = data_train.loc[:data_train.shape[0]*4//5, [\"Market value\"]]\n",
    "\n",
    "#Transpose to get correct dimensions\n",
    "X_lin_train = X_train_final.to_numpy().T\n",
    "Y_lin_train = y_train.to_numpy().reshape(-1,1).T\n",
    "\n",
    "X_lin_test = X_test_final.to_numpy().T\n",
    "Y_lin_test = y_test.to_numpy().reshape(-1,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613561f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_parameters(layers_units):\n",
    "    parameters = {}            # create a dictionary containing the parameters\n",
    "    for l in range(1, len(layers_units)):\n",
    "        parameters['W' + str(l)] = 0.001* np.random.randn(layers_units[l],layers_units[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layers_units[l],1))\n",
    "    return parameters\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def relu(z, deriv = False):\n",
    "    if(deriv):\n",
    "        return z>0\n",
    "    else:\n",
    "        return np.multiply(z, z>0)\n",
    "    \n",
    "def forward_propagation(X,parameters,linear):\n",
    "    cache = {}\n",
    "    L = len(parameters)//2 #final layer\n",
    "    cache[\"A0\"] = X #ease of notation since input = layer 0\n",
    "    for l in range(1, L):\n",
    "        cache['Z' + str(l)] = np.dot(parameters['W' + str(l)],cache['A' + str(l-1)]) + parameters['b' + str(l)]\n",
    "        cache['A' + str(l)] = relu(cache['Z' + str(l)])\n",
    "    #final layer\n",
    "    cache['Z' + str(L)] = np.dot(parameters['W' + str(L)],cache['A' + str(L-1)]) + parameters['b' + str(L)]\n",
    "    cache['A' + str(L)] =cache['Z' + str(L)] if linear else sigmoid(cache['Z' + str(L)])\n",
    "    return cache \n",
    "\n",
    "def cost_function(AL,Y, linear):\n",
    "    m = Y.shape[1]\n",
    "    if linear:\n",
    "        cost = (1/(2*m))*(np.sum(np.square(AL-Y)))\n",
    "    else:\n",
    "        cost = (-1/m)*( np.sum(np.multiply(Y,np.log(AL))) + np.sum(np.multiply((1-Y),np.log(1-AL))))\n",
    "    return cost\n",
    "\n",
    "def backpropagation(cache,Y,parameters):\n",
    "    L = len(parameters)//2 \n",
    "    m = Y.shape[1]\n",
    "    grads = {}\n",
    "    grads[\"dZ\" + str(L)]= cache[\"A\" + str(L)] - Y\n",
    "    grads[\"dW\" + str(L)]= (1/m)*np.dot(grads[\"dZ\" + str(L)],cache[\"A\" + str(L-1)].T) \n",
    "    grads[\"db\" + str(L)]= (1/m)*np.sum(grads[\"dZ\" + str(L)],axis=1,keepdims=True)\n",
    "    for l in range(L-1,0,-1):\n",
    "        grads[\"dA\" + str(l)]= np.dot(parameters[\"W\" + str(l+1)].T,grads[\"dZ\" + str(l+1)])\n",
    "        grads[\"dZ\" + str(l)]= np.multiply(grads[\"dA\" + str(l)], relu(cache[\"Z\" + str(l)], deriv = True))\n",
    "        grads[\"dW\" + str(l)]= (1/m)*np.dot(grads[\"dZ\" + str(l)],cache[\"A\" + str(l-1)].T) \n",
    "        grads[\"db\" + str(l)]= (1/m)*np.sum(grads[\"dZ\" + str(l)],axis=1,keepdims=True)\n",
    "    return grads\n",
    "\n",
    "def F1_score(AL, Y):\n",
    "    prediction = (AL >= (np.ones_like(AL)/2))\n",
    "    \n",
    "    truth_pos = (Y == np.ones_like(Y))\n",
    "    truth_neg = (Y == np.zeros_like(Y))\n",
    "    pred_pos = (prediction == np.ones_like(prediction))\n",
    "    pred_neg = (prediction == np.zeros_like(prediction))\n",
    "\n",
    "    true_pos = np.sum(np.logical_and(truth_pos,pred_pos))\n",
    "    if true_pos == 0: #This prevents an undefined computation since precision=recall=0 \n",
    "        return 0\n",
    "    false_pos =np.sum(np.logical_and(truth_neg,pred_pos))\n",
    "    false_neg =np.sum(np.logical_and(truth_pos,pred_neg))\n",
    "    true_neg =np.sum(np.logical_and(truth_neg,pred_neg))\n",
    "\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = (true_pos)/(true_pos + false_neg)\n",
    "    F1_score = 2*(recall*precision) /(recall + precision)\n",
    "    return F1_score\n",
    "\n",
    "def evaluation_metric(AL, Y, linear):\n",
    "    if linear:\n",
    "        return cost_function(AL,Y,linear) #MSE for regression\n",
    "    else:\n",
    "        return F1_score(AL, Y) #F1 score for classification\n",
    "    \n",
    "def train_model(X_train, Y_train,num_epochs,layers_units,learning_rate, linear):\n",
    "    train_costs = []\n",
    "    \n",
    "    parameters = initialise_parameters(layers_units)\n",
    "    L = len(layers_units)-1 \n",
    "    for epoch in range (num_epochs):\n",
    "        #perform one cycle of forward and backward propagation to get the partial derivatives w.r.t. the weights\n",
    "        #and biases. Calculate the cost - used to monitor training\n",
    "        cache = forward_propagation(X_train,parameters,linear)\n",
    "        cost = cost_function(cache[\"A\" + str(L)],Y_train,linear)\n",
    "        grads = backpropagation(cache,Y_train,parameters)\n",
    "\n",
    "        #update the parameters using gradient descent\n",
    "        for l in range(1,L+1):\n",
    "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"dW\" + str(l)]\n",
    "            parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*grads[\"db\" + str(l)]\n",
    "\n",
    "        #periodically output an update on the current cost and performance on the dev set for visualisation\n",
    "        train_costs.append(cost)\n",
    "        if(epoch%(num_epochs//10)==0):\n",
    "            print(\"Training the model, epoch: \" + str(epoch+1))\n",
    "            print(\"Cost after epoch \" + str((epoch)) + \": \" + str(cost))\n",
    "    print(\"Training complete!\")\n",
    "    #return the trained parameters and the visualisation metrics\n",
    "    return parameters, train_costs\n",
    "\n",
    "def evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test, linear):\n",
    "    #plot the graphs of training set error\n",
    "    plt.plot(np.squeeze(train_costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Training Set Error\")\n",
    "    plt.show()\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    #For train and test sets, perform a step of forward propagation to obtain the trained model's \n",
    "    #predictions and evaluate this with an F1 score.\n",
    "    train_cache = forward_propagation(X_train,parameters,linear)\n",
    "    train_AL = train_cache[\"A\"+ str(L)]\n",
    "    if linear: \n",
    "         print(\"The train set MSE is: \"+str(evaluation_metric(train_AL,Y_train, linear)))\n",
    "    else:\n",
    "        print(\"The train set F1 score is: \"+str(evaluation_metric(train_AL,Y_train, linear)))\n",
    "    \n",
    "    test_cache = forward_propagation(X_test,parameters, linear)\n",
    "    test_AL = test_cache[\"A\"+ str(L)]\n",
    "    if linear:\n",
    "                print(\"The test set MSE is: \"+str(evaluation_metric(test_AL,Y_test, linear)))\n",
    "    else:\n",
    "        print(\"The test set F1 score is: \"+str(evaluation_metric(test_AL,Y_test, linear)))\n",
    "\n",
    "def run_model(X_train, Y_train, X_test, Y_test, hyperparameters, linear=True):\n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "    layers_units = hyperparameters[\"layers_units\"]\n",
    "    learning_rate = hyperparameters[\"learning_rate\"]\n",
    "    \n",
    "    parameters, train_costs = train_model(X_train, Y_train ,num_epochs,layers_units,learning_rate,linear)         \n",
    "    evaluate_model(train_costs,parameters,X_train, Y_train, X_test, Y_test,linear)\n",
    "\n",
    "#define the hyperparameters for the model\n",
    "def create_hyperparameters(X, num_epochs):\n",
    "    hyperparameters={}\n",
    "    hyperparameters[\"num_epochs\"] = num_epochs #number of passes through the training set\n",
    "    hyperparameters[\"layers_units\"] = [X.shape[0], 64, 64,32, 1] #layer 0 is the input layer\n",
    "    hyperparameters[\"learning_rate\"] = 1e-3\n",
    "    return hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = create_hyperparameters(X_lin_train, 1000)\n",
    "run_model(X_lin_train, Y_lin_train, X_lin_test, Y_lin_test,hyperparameters, linear=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
